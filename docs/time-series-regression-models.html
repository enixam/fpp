<!DOCTYPE html>
<html lang="" xml:lang="">
<head>

  <meta charset="utf-8" />
  <meta http-equiv="X-UA-Compatible" content="IE=edge" />
  <title>Chapter 7 Time series regression models | Notes for “Forecasting: Principles and Practice, 3rd edition”</title>
  <meta name="description" content="“Reproducing”Forecasting: Principles and Practice, 3rd edition"" />
  <meta name="generator" content="bookdown 0.20 and GitBook 2.6.7" />

  <meta property="og:title" content="Chapter 7 Time series regression models | Notes for “Forecasting: Principles and Practice, 3rd edition”" />
  <meta property="og:type" content="book" />
  
  
  <meta property="og:description" content="“Reproducing”Forecasting: Principles and Practice, 3rd edition"" />
  <meta name="github-repo" content="enixam/fpp" />

  <meta name="twitter:card" content="summary" />
  <meta name="twitter:title" content="Chapter 7 Time series regression models | Notes for “Forecasting: Principles and Practice, 3rd edition”" />
  
  <meta name="twitter:description" content="“Reproducing”Forecasting: Principles and Practice, 3rd edition"" />
  

<meta name="author" content="Qiushi Yan" />


<meta name="date" content="2020-09-29" />

  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <meta name="apple-mobile-web-app-capable" content="yes" />
  <meta name="apple-mobile-web-app-status-bar-style" content="black" />
  
  
<link rel="prev" href="judgmental-forecasts.html"/>
<link rel="next" href="exponential-smoothing.html"/>
<script src="libs/jquery-2.2.3/jquery.min.js"></script>
<link href="libs/gitbook-2.6.7/css/style.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-table.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-bookdown.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-highlight.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-search.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-fontsettings.css" rel="stylesheet" />
<link href="libs/gitbook-2.6.7/css/plugin-clipboard.css" rel="stylesheet" />









<script src="libs/accessible-code-block-0.0.1/empty-anchor.js"></script>


<style type="text/css">
code.sourceCode > span { display: inline-block; line-height: 1.25; }
code.sourceCode > span { color: inherit; text-decoration: inherit; }
code.sourceCode > span:empty { height: 1.2em; }
.sourceCode { overflow: visible; }
code.sourceCode { white-space: pre; position: relative; }
pre.sourceCode { margin: 0; }
@media screen {
div.sourceCode { overflow: auto; }
}
@media print {
code.sourceCode { white-space: pre-wrap; }
code.sourceCode > span { text-indent: -5em; padding-left: 5em; }
}
pre.numberSource code
  { counter-reset: source-line 0; }
pre.numberSource code > span
  { position: relative; left: -4em; counter-increment: source-line; }
pre.numberSource code > span > a:first-child::before
  { content: counter(source-line);
    position: relative; left: -1em; text-align: right; vertical-align: baseline;
    border: none; display: inline-block;
    -webkit-touch-callout: none; -webkit-user-select: none;
    -khtml-user-select: none; -moz-user-select: none;
    -ms-user-select: none; user-select: none;
    padding: 0 4px; width: 4em;
    color: #aaaaaa;
  }
pre.numberSource { margin-left: 3em; border-left: 1px solid #aaaaaa;  padding-left: 4px; }
div.sourceCode
  {   }
@media screen {
code.sourceCode > span > a:first-child::before { text-decoration: underline; }
}
code span.al { color: #ff0000; font-weight: bold; } /* Alert */
code span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code span.at { color: #7d9029; } /* Attribute */
code span.bn { color: #40a070; } /* BaseN */
code span.bu { } /* BuiltIn */
code span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code span.ch { color: #4070a0; } /* Char */
code span.cn { color: #880000; } /* Constant */
code span.co { color: #60a0b0; font-style: italic; } /* Comment */
code span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code span.do { color: #ba2121; font-style: italic; } /* Documentation */
code span.dt { color: #902000; } /* DataType */
code span.dv { color: #40a070; } /* DecVal */
code span.er { color: #ff0000; font-weight: bold; } /* Error */
code span.ex { } /* Extension */
code span.fl { color: #40a070; } /* Float */
code span.fu { color: #06287e; } /* Function */
code span.im { } /* Import */
code span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */
code span.kw { color: #007020; font-weight: bold; } /* Keyword */
code span.op { color: #666666; } /* Operator */
code span.ot { color: #007020; } /* Other */
code span.pp { color: #bc7a00; } /* Preprocessor */
code span.sc { color: #4070a0; } /* SpecialChar */
code span.ss { color: #bb6688; } /* SpecialString */
code span.st { color: #4070a0; } /* String */
code span.va { color: #19177c; } /* Variable */
code span.vs { color: #4070a0; } /* VerbatimString */
code span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
</style>

<link rel="stylesheet" href="css\style.css" type="text/css" />
</head>

<body>



  <div class="book without-animation with-summary font-size-2 font-family-1" data-basepath=".">

    <div class="book-summary">
      <nav role="navigation">

<ul class="summary">
<li><a href="./">Notes for fpp3</a></li>

<li class="divider"></li>
<li class="chapter" data-level="" data-path="index.html"><a href="index.html"><i class="fa fa-check"></i>Preface</a></li>
<li class="chapter" data-level="1" data-path="getting-started.html"><a href="getting-started.html"><i class="fa fa-check"></i><b>1</b> Getting started</a></li>
<li class="chapter" data-level="2" data-path="time-series-graphics.html"><a href="time-series-graphics.html"><i class="fa fa-check"></i><b>2</b> Time series graphics</a><ul>
<li class="chapter" data-level="2.1" data-path="time-series-graphics.html"><a href="time-series-graphics.html#tsibble-objects"><i class="fa fa-check"></i><b>2.1</b> <code>tsibble</code> objects</a><ul>
<li class="chapter" data-level="2.1.1" data-path="time-series-graphics.html"><a href="time-series-graphics.html#manipulation"><i class="fa fa-check"></i><b>2.1.1</b> manipulation</a></li>
<li class="chapter" data-level="2.1.2" data-path="time-series-graphics.html"><a href="time-series-graphics.html#importing"><i class="fa fa-check"></i><b>2.1.2</b> importing</a></li>
</ul></li>
<li class="chapter" data-level="2.2" data-path="time-series-graphics.html"><a href="time-series-graphics.html#time-plots"><i class="fa fa-check"></i><b>2.2</b> Time plots</a></li>
<li class="chapter" data-level="2.3" data-path="time-series-graphics.html"><a href="time-series-graphics.html#patterns-of-time-series-trend-seasonal-and-cyclic"><i class="fa fa-check"></i><b>2.3</b> Patterns of time series: trend, seasonal and cyclic</a></li>
<li class="chapter" data-level="2.4" data-path="time-series-graphics.html"><a href="time-series-graphics.html#seasonal-plots"><i class="fa fa-check"></i><b>2.4</b> Seasonal plots</a><ul>
<li class="chapter" data-level="2.4.1" data-path="time-series-graphics.html"><a href="time-series-graphics.html#multiple-seasonal-periods-period-in-gg_season"><i class="fa fa-check"></i><b>2.4.1</b> Multiple seasonal periods: <code>period</code> in <code>gg_season()</code></a></li>
</ul></li>
<li class="chapter" data-level="2.5" data-path="time-series-graphics.html"><a href="time-series-graphics.html#seasonal-subseries-plots"><i class="fa fa-check"></i><b>2.5</b> Seasonal subseries plots</a><ul>
<li class="chapter" data-level="2.5.1" data-path="time-series-graphics.html"><a href="time-series-graphics.html#example-australian-holiday-tourism"><i class="fa fa-check"></i><b>2.5.1</b> Example: Australian holiday tourism</a></li>
</ul></li>
<li class="chapter" data-level="2.6" data-path="time-series-graphics.html"><a href="time-series-graphics.html#visualization-between-time-series"><i class="fa fa-check"></i><b>2.6</b> Visualization between time series</a><ul>
<li class="chapter" data-level="2.6.1" data-path="time-series-graphics.html"><a href="time-series-graphics.html#scatterplot-matrices"><i class="fa fa-check"></i><b>2.6.1</b> scatterplot matrices</a></li>
</ul></li>
<li class="chapter" data-level="2.7" data-path="time-series-graphics.html"><a href="time-series-graphics.html#lag-plots"><i class="fa fa-check"></i><b>2.7</b> Lag plots</a><ul>
<li class="chapter" data-level="2.7.1" data-path="time-series-graphics.html"><a href="time-series-graphics.html#autocorrelation"><i class="fa fa-check"></i><b>2.7.1</b> Autocorrelation</a></li>
<li class="chapter" data-level="2.7.2" data-path="time-series-graphics.html"><a href="time-series-graphics.html#trend-and-seasonality-in-acf-plots"><i class="fa fa-check"></i><b>2.7.2</b> Trend and seasonality in ACF plots</a></li>
</ul></li>
<li class="chapter" data-level="2.8" data-path="time-series-graphics.html"><a href="time-series-graphics.html#calendar-plots"><i class="fa fa-check"></i><b>2.8</b> Calendar plots</a></li>
</ul></li>
<li class="chapter" data-level="3" data-path="time-series-decomposition.html"><a href="time-series-decomposition.html"><i class="fa fa-check"></i><b>3</b> Time series decomposition</a><ul>
<li class="chapter" data-level="3.1" data-path="time-series-decomposition.html"><a href="time-series-decomposition.html#transformation-and-adjustments"><i class="fa fa-check"></i><b>3.1</b> Transformation and adjustments</a><ul>
<li class="chapter" data-level="3.1.1" data-path="time-series-decomposition.html"><a href="time-series-decomposition.html#calendar-adjustments"><i class="fa fa-check"></i><b>3.1.1</b> Calendar adjustments</a></li>
<li class="chapter" data-level="3.1.2" data-path="time-series-decomposition.html"><a href="time-series-decomposition.html#population-adjustments"><i class="fa fa-check"></i><b>3.1.2</b> Population adjustments</a></li>
<li class="chapter" data-level="3.1.3" data-path="time-series-decomposition.html"><a href="time-series-decomposition.html#inflation-adjustments"><i class="fa fa-check"></i><b>3.1.3</b> Inflation adjustments</a></li>
<li class="chapter" data-level="3.1.4" data-path="time-series-decomposition.html"><a href="time-series-decomposition.html#box-cox"><i class="fa fa-check"></i><b>3.1.4</b> Mathematical transformation (Box-Cox)</a></li>
</ul></li>
<li class="chapter" data-level="3.2" data-path="time-series-decomposition.html"><a href="time-series-decomposition.html#moving-averages"><i class="fa fa-check"></i><b>3.2</b> Moving averages</a><ul>
<li class="chapter" data-level="3.2.1" data-path="time-series-decomposition.html"><a href="time-series-decomposition.html#moving-averages-of-moving-averages"><i class="fa fa-check"></i><b>3.2.1</b> Moving averages of moving averages</a></li>
<li class="chapter" data-level="3.2.2" data-path="time-series-decomposition.html"><a href="time-series-decomposition.html#estimating-the-trend-cycle-component-with-seasonal-data"><i class="fa fa-check"></i><b>3.2.2</b> Estimating the trend-cycle component with seasonal data</a></li>
<li class="chapter" data-level="3.2.3" data-path="time-series-decomposition.html"><a href="time-series-decomposition.html#weighted-moving-averages"><i class="fa fa-check"></i><b>3.2.3</b> Weighted moving averages</a></li>
</ul></li>
<li class="chapter" data-level="3.3" data-path="time-series-decomposition.html"><a href="time-series-decomposition.html#classical-decomposition"><i class="fa fa-check"></i><b>3.3</b> Classical decomposition</a></li>
<li class="chapter" data-level="3.4" data-path="time-series-decomposition.html"><a href="time-series-decomposition.html#x11-decomposition"><i class="fa fa-check"></i><b>3.4</b> X11 decomposition</a></li>
<li class="chapter" data-level="3.5" data-path="time-series-decomposition.html"><a href="time-series-decomposition.html#seats-decomposition"><i class="fa fa-check"></i><b>3.5</b> SEATS decomposition</a></li>
<li class="chapter" data-level="3.6" data-path="time-series-decomposition.html"><a href="time-series-decomposition.html#stl-decomposition"><i class="fa fa-check"></i><b>3.6</b> STL decomposition</a></li>
</ul></li>
<li class="chapter" data-level="4" data-path="time-series-features.html"><a href="time-series-features.html"><i class="fa fa-check"></i><b>4</b> Time series features</a><ul>
<li class="chapter" data-level="4.1" data-path="time-series-features.html"><a href="time-series-features.html#simple-statistics"><i class="fa fa-check"></i><b>4.1</b> Simple statistics</a></li>
<li class="chapter" data-level="4.2" data-path="time-series-features.html"><a href="time-series-features.html#acf-features"><i class="fa fa-check"></i><b>4.2</b> ACF features</a></li>
<li class="chapter" data-level="4.3" data-path="time-series-features.html"><a href="time-series-features.html#stl-features"><i class="fa fa-check"></i><b>4.3</b> STL features</a></li>
<li class="chapter" data-level="4.4" data-path="time-series-features.html"><a href="time-series-features.html#other-features"><i class="fa fa-check"></i><b>4.4</b> Other features</a></li>
<li class="chapter" data-level="4.5" data-path="time-series-features.html"><a href="time-series-features.html#exporing-australian-tourism-data"><i class="fa fa-check"></i><b>4.5</b> Exporing Australian tourism data</a></li>
</ul></li>
<li class="chapter" data-level="5" data-path="the-forecasters-toolbox.html"><a href="the-forecasters-toolbox.html"><i class="fa fa-check"></i><b>5</b> The forecaster’s toolbox</a><ul>
<li class="chapter" data-level="5.1" data-path="the-forecasters-toolbox.html"><a href="the-forecasters-toolbox.html#a-tidy-forecasting-workflow"><i class="fa fa-check"></i><b>5.1</b> A tidy forecasting workflow</a><ul>
<li class="chapter" data-level="5.1.1" data-path="the-forecasters-toolbox.html"><a href="the-forecasters-toolbox.html#data-preparation-tidy"><i class="fa fa-check"></i><b>5.1.1</b> Data preparation (tidy)</a></li>
<li class="chapter" data-level="5.1.2" data-path="the-forecasters-toolbox.html"><a href="the-forecasters-toolbox.html#visualize"><i class="fa fa-check"></i><b>5.1.2</b> Visualize</a></li>
<li class="chapter" data-level="5.1.3" data-path="the-forecasters-toolbox.html"><a href="the-forecasters-toolbox.html#define-a-model-specify"><i class="fa fa-check"></i><b>5.1.3</b> Define a model (specify)</a></li>
<li class="chapter" data-level="5.1.4" data-path="the-forecasters-toolbox.html"><a href="the-forecasters-toolbox.html#train-the-model-estimate"><i class="fa fa-check"></i><b>5.1.4</b> Train the model (estimate)</a></li>
<li class="chapter" data-level="5.1.5" data-path="the-forecasters-toolbox.html"><a href="the-forecasters-toolbox.html#check-model-performance-evaluate"><i class="fa fa-check"></i><b>5.1.5</b> Check model performance (evaluate)</a></li>
<li class="chapter" data-level="5.1.6" data-path="the-forecasters-toolbox.html"><a href="the-forecasters-toolbox.html#produce-forecasts-forecast"><i class="fa fa-check"></i><b>5.1.6</b> Produce forecasts (forecast)</a></li>
</ul></li>
<li class="chapter" data-level="5.2" data-path="the-forecasters-toolbox.html"><a href="the-forecasters-toolbox.html#some-simple-forecasting-methods"><i class="fa fa-check"></i><b>5.2</b> Some simple forecasting methods</a><ul>
<li class="chapter" data-level="5.2.1" data-path="the-forecasters-toolbox.html"><a href="the-forecasters-toolbox.html#mean-method"><i class="fa fa-check"></i><b>5.2.1</b> Mean method</a></li>
<li class="chapter" data-level="5.2.2" data-path="the-forecasters-toolbox.html"><a href="the-forecasters-toolbox.html#naive-method"><i class="fa fa-check"></i><b>5.2.2</b> Naive method</a></li>
<li class="chapter" data-level="5.2.3" data-path="the-forecasters-toolbox.html"><a href="the-forecasters-toolbox.html#seasonal-naive-method"><i class="fa fa-check"></i><b>5.2.3</b> Seasonal naive method</a></li>
<li class="chapter" data-level="5.2.4" data-path="the-forecasters-toolbox.html"><a href="the-forecasters-toolbox.html#drift-method"><i class="fa fa-check"></i><b>5.2.4</b> Drift method</a></li>
<li class="chapter" data-level="5.2.5" data-path="the-forecasters-toolbox.html"><a href="the-forecasters-toolbox.html#australian-quarterly-beer-production"><i class="fa fa-check"></i><b>5.2.5</b> Australian quarterly beer production</a></li>
<li class="chapter" data-level="5.2.6" data-path="the-forecasters-toolbox.html"><a href="the-forecasters-toolbox.html#example-googles-daily-closing-stock-price"><i class="fa fa-check"></i><b>5.2.6</b> Example: Google’s daily closing stock price</a></li>
</ul></li>
<li class="chapter" data-level="5.3" data-path="the-forecasters-toolbox.html"><a href="the-forecasters-toolbox.html#fitted-values-and-residuals"><i class="fa fa-check"></i><b>5.3</b> Fitted values and residuals</a><ul>
<li class="chapter" data-level="5.3.1" data-path="the-forecasters-toolbox.html"><a href="the-forecasters-toolbox.html#residuals"><i class="fa fa-check"></i><b>5.3.1</b> Residuals</a></li>
</ul></li>
<li class="chapter" data-level="5.4" data-path="the-forecasters-toolbox.html"><a href="the-forecasters-toolbox.html#residual-diagnostics"><i class="fa fa-check"></i><b>5.4</b> Residual diagnostics</a><ul>
<li class="chapter" data-level="5.4.1" data-path="the-forecasters-toolbox.html"><a href="the-forecasters-toolbox.html#white-noise"><i class="fa fa-check"></i><b>5.4.1</b> White noise</a></li>
<li class="chapter" data-level="5.4.2" data-path="the-forecasters-toolbox.html"><a href="the-forecasters-toolbox.html#example-forecasting-the-google-daily-closing-stock-price"><i class="fa fa-check"></i><b>5.4.2</b> Example: Forecasting the Google daily closing stock price</a></li>
<li class="chapter" data-level="5.4.3" data-path="the-forecasters-toolbox.html"><a href="the-forecasters-toolbox.html#portmanteau-tests-for-autocorrelation"><i class="fa fa-check"></i><b>5.4.3</b> Portmanteau tests for autocorrelation</a></li>
</ul></li>
<li class="chapter" data-level="5.5" data-path="the-forecasters-toolbox.html"><a href="the-forecasters-toolbox.html#predict-interval"><i class="fa fa-check"></i><b>5.5</b> Prediction intervals</a><ul>
<li class="chapter" data-level="5.5.1" data-path="the-forecasters-toolbox.html"><a href="the-forecasters-toolbox.html#one-step-prediction-intervals"><i class="fa fa-check"></i><b>5.5.1</b> One-step prediction intervals</a></li>
<li class="chapter" data-level="5.5.2" data-path="the-forecasters-toolbox.html"><a href="the-forecasters-toolbox.html#multi-step-prediction-intervals"><i class="fa fa-check"></i><b>5.5.2</b> Multi-step prediction intervals</a></li>
<li class="chapter" data-level="5.5.3" data-path="the-forecasters-toolbox.html"><a href="the-forecasters-toolbox.html#prediction-intervals-from-bootstrapped-residuals"><i class="fa fa-check"></i><b>5.5.3</b> Prediction intervals from bootstrapped residuals</a></li>
</ul></li>
<li class="chapter" data-level="5.6" data-path="the-forecasters-toolbox.html"><a href="the-forecasters-toolbox.html#evaluating-model-accuracy"><i class="fa fa-check"></i><b>5.6</b> Evaluating model accuracy</a><ul>
<li class="chapter" data-level="5.6.1" data-path="the-forecasters-toolbox.html"><a href="the-forecasters-toolbox.html#forecast-errors"><i class="fa fa-check"></i><b>5.6.1</b> Forecast errors</a></li>
<li class="chapter" data-level="5.6.2" data-path="the-forecasters-toolbox.html"><a href="the-forecasters-toolbox.html#scale-dependent-errors"><i class="fa fa-check"></i><b>5.6.2</b> Scale dependent errors</a></li>
<li class="chapter" data-level="5.6.3" data-path="the-forecasters-toolbox.html"><a href="the-forecasters-toolbox.html#percentage-errors"><i class="fa fa-check"></i><b>5.6.3</b> Percentage errors</a></li>
<li class="chapter" data-level="5.6.4" data-path="the-forecasters-toolbox.html"><a href="the-forecasters-toolbox.html#scaled-errors"><i class="fa fa-check"></i><b>5.6.4</b> Scaled errors</a></li>
<li class="chapter" data-level="5.6.5" data-path="the-forecasters-toolbox.html"><a href="the-forecasters-toolbox.html#examples-beer-production"><i class="fa fa-check"></i><b>5.6.5</b> Examples: beer production</a></li>
</ul></li>
<li class="chapter" data-level="5.7" data-path="the-forecasters-toolbox.html"><a href="the-forecasters-toolbox.html#time-series-cross-validation"><i class="fa fa-check"></i><b>5.7</b> Time series cross-validation</a><ul>
<li class="chapter" data-level="5.7.1" data-path="the-forecasters-toolbox.html"><a href="the-forecasters-toolbox.html#example-forecast-horizon-accuracy-with-cross-validation"><i class="fa fa-check"></i><b>5.7.1</b> Example: Forecast horizon accuracy with cross-validation</a></li>
</ul></li>
<li class="chapter" data-level="5.8" data-path="the-forecasters-toolbox.html"><a href="the-forecasters-toolbox.html#forecasting-using-transformations"><i class="fa fa-check"></i><b>5.8</b> Forecasting using transformations</a><ul>
<li class="chapter" data-level="5.8.1" data-path="the-forecasters-toolbox.html"><a href="the-forecasters-toolbox.html#prediction-intervals-with-transformations"><i class="fa fa-check"></i><b>5.8.1</b> Prediction intervals with transformations</a></li>
<li class="chapter" data-level="5.8.2" data-path="the-forecasters-toolbox.html"><a href="the-forecasters-toolbox.html#forecasting-with-constraints"><i class="fa fa-check"></i><b>5.8.2</b> Forecasting with constraints</a></li>
<li class="chapter" data-level="5.8.3" data-path="the-forecasters-toolbox.html"><a href="the-forecasters-toolbox.html#bias-adjustments"><i class="fa fa-check"></i><b>5.8.3</b> Bias adjustments</a></li>
</ul></li>
<li class="chapter" data-level="5.9" data-path="the-forecasters-toolbox.html"><a href="the-forecasters-toolbox.html#forecasting-with-decomposition"><i class="fa fa-check"></i><b>5.9</b> Forecasting with decomposition</a><ul>
<li class="chapter" data-level="5.9.1" data-path="the-forecasters-toolbox.html"><a href="the-forecasters-toolbox.html#example-employment-in-the-us-retail-sector"><i class="fa fa-check"></i><b>5.9.1</b> Example: Employment in the US retail sector</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="6" data-path="judgmental-forecasts.html"><a href="judgmental-forecasts.html"><i class="fa fa-check"></i><b>6</b> Judgmental forecasts</a><ul>
<li class="chapter" data-level="6.1" data-path="judgmental-forecasts.html"><a href="judgmental-forecasts.html#beware-of-limitations"><i class="fa fa-check"></i><b>6.1</b> Beware of limitations</a></li>
<li class="chapter" data-level="6.2" data-path="judgmental-forecasts.html"><a href="judgmental-forecasts.html#key-principles"><i class="fa fa-check"></i><b>6.2</b> Key principles</a></li>
<li class="chapter" data-level="6.3" data-path="judgmental-forecasts.html"><a href="judgmental-forecasts.html#the-delphi-method"><i class="fa fa-check"></i><b>6.3</b> The Delphi method</a><ul>
<li class="chapter" data-level="6.3.1" data-path="judgmental-forecasts.html"><a href="judgmental-forecasts.html#experts-and-anonymity"><i class="fa fa-check"></i><b>6.3.1</b> Experts and anonymity</a></li>
<li class="chapter" data-level="6.3.2" data-path="judgmental-forecasts.html"><a href="judgmental-forecasts.html#setting-the-forecasting-task-in-a-delphi"><i class="fa fa-check"></i><b>6.3.2</b> Setting the forecasting task in a Delphi</a></li>
<li class="chapter" data-level="6.3.3" data-path="judgmental-forecasts.html"><a href="judgmental-forecasts.html#iteration"><i class="fa fa-check"></i><b>6.3.3</b> Iteration</a></li>
<li class="chapter" data-level="6.3.4" data-path="judgmental-forecasts.html"><a href="judgmental-forecasts.html#final-forecasts"><i class="fa fa-check"></i><b>6.3.4</b> Final forecasts</a></li>
<li class="chapter" data-level="6.3.5" data-path="judgmental-forecasts.html"><a href="judgmental-forecasts.html#limitations-and-variations"><i class="fa fa-check"></i><b>6.3.5</b> Limitations and variations</a></li>
<li class="chapter" data-level="6.3.6" data-path="judgmental-forecasts.html"><a href="judgmental-forecasts.html#the-facilitator"><i class="fa fa-check"></i><b>6.3.6</b> The facilitator</a></li>
</ul></li>
<li class="chapter" data-level="6.4" data-path="judgmental-forecasts.html"><a href="judgmental-forecasts.html#forecasting-by-analogy"><i class="fa fa-check"></i><b>6.4</b> Forecasting by analogy</a></li>
<li class="chapter" data-level="6.5" data-path="judgmental-forecasts.html"><a href="judgmental-forecasts.html#scenario-forecasting"><i class="fa fa-check"></i><b>6.5</b> Scenario forecasting</a></li>
<li class="chapter" data-level="6.6" data-path="judgmental-forecasts.html"><a href="judgmental-forecasts.html#new-product-forecasting"><i class="fa fa-check"></i><b>6.6</b> New product forecasting</a><ul>
<li class="chapter" data-level="6.6.1" data-path="judgmental-forecasts.html"><a href="judgmental-forecasts.html#sales-force-composite"><i class="fa fa-check"></i><b>6.6.1</b> Sales force composite</a></li>
<li class="chapter" data-level="6.6.2" data-path="judgmental-forecasts.html"><a href="judgmental-forecasts.html#executive-opinion"><i class="fa fa-check"></i><b>6.6.2</b> Executive opinion</a></li>
<li class="chapter" data-level="6.6.3" data-path="judgmental-forecasts.html"><a href="judgmental-forecasts.html#customer-intentions"><i class="fa fa-check"></i><b>6.6.3</b> Customer intentions</a></li>
</ul></li>
<li class="chapter" data-level="6.7" data-path="judgmental-forecasts.html"><a href="judgmental-forecasts.html#judgmental-adjustments"><i class="fa fa-check"></i><b>6.7</b> Judgmental adjustments</a><ul>
<li class="chapter" data-level="6.7.1" data-path="judgmental-forecasts.html"><a href="judgmental-forecasts.html#use-adjustments-sparingly"><i class="fa fa-check"></i><b>6.7.1</b> Use adjustments sparingly</a></li>
<li class="chapter" data-level="6.7.2" data-path="judgmental-forecasts.html"><a href="judgmental-forecasts.html#apply-a-structured-approach"><i class="fa fa-check"></i><b>6.7.2</b> Apply a structured approach</a></li>
<li class="chapter" data-level="6.7.3" data-path="judgmental-forecasts.html"><a href="judgmental-forecasts.html#example-tourism-forecasting-committee-tfc"><i class="fa fa-check"></i><b>6.7.3</b> Example: Tourism Forecasting Committee (TFC)</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="7" data-path="time-series-regression-models.html"><a href="time-series-regression-models.html"><i class="fa fa-check"></i><b>7</b> Time series regression models</a><ul>
<li class="chapter" data-level="7.1" data-path="time-series-regression-models.html"><a href="time-series-regression-models.html#the-linear-model"><i class="fa fa-check"></i><b>7.1</b> The linear model</a><ul>
<li class="chapter" data-level="7.1.1" data-path="time-series-regression-models.html"><a href="time-series-regression-models.html#simple-linear-regression"><i class="fa fa-check"></i><b>7.1.1</b> Simple linear regression</a></li>
<li class="chapter" data-level="7.1.2" data-path="time-series-regression-models.html"><a href="time-series-regression-models.html#multiple-linear-regression"><i class="fa fa-check"></i><b>7.1.2</b> Multiple linear regression</a></li>
<li class="chapter" data-level="7.1.3" data-path="time-series-regression-models.html"><a href="time-series-regression-models.html#assumptions"><i class="fa fa-check"></i><b>7.1.3</b> Assumptions</a></li>
</ul></li>
<li class="chapter" data-level="7.2" data-path="time-series-regression-models.html"><a href="time-series-regression-models.html#least-squares-estimation"><i class="fa fa-check"></i><b>7.2</b> Least squares estimation</a><ul>
<li class="chapter" data-level="7.2.1" data-path="time-series-regression-models.html"><a href="time-series-regression-models.html#fitted-values"><i class="fa fa-check"></i><b>7.2.1</b> Fitted values</a></li>
<li class="chapter" data-level="7.2.2" data-path="time-series-regression-models.html"><a href="time-series-regression-models.html#goodness-of-fit"><i class="fa fa-check"></i><b>7.2.2</b> Goodness of fit</a></li>
<li class="chapter" data-level="7.2.3" data-path="time-series-regression-models.html"><a href="time-series-regression-models.html#standard-error-of-the-regression"><i class="fa fa-check"></i><b>7.2.3</b> Standard error of the regression</a></li>
</ul></li>
<li class="chapter" data-level="7.3" data-path="time-series-regression-models.html"><a href="time-series-regression-models.html#evaluating-a-regression-model"><i class="fa fa-check"></i><b>7.3</b> Evaluating a regression model</a><ul>
<li class="chapter" data-level="7.3.1" data-path="time-series-regression-models.html"><a href="time-series-regression-models.html#residual-plots-against-predictors"><i class="fa fa-check"></i><b>7.3.1</b> Residual plots against predictors</a></li>
<li class="chapter" data-level="7.3.2" data-path="time-series-regression-models.html"><a href="time-series-regression-models.html#residual-plots-against-fitted-values"><i class="fa fa-check"></i><b>7.3.2</b> Residual plots against fitted values</a></li>
<li class="chapter" data-level="7.3.3" data-path="time-series-regression-models.html"><a href="time-series-regression-models.html#outliers-and-influential-observations"><i class="fa fa-check"></i><b>7.3.3</b> Outliers and influential observations</a></li>
<li class="chapter" data-level="7.3.4" data-path="time-series-regression-models.html"><a href="time-series-regression-models.html#the-performance-package"><i class="fa fa-check"></i><b>7.3.4</b> The <code>performance</code> package</a></li>
<li class="chapter" data-level="7.3.5" data-path="time-series-regression-models.html"><a href="time-series-regression-models.html#spurious-regression"><i class="fa fa-check"></i><b>7.3.5</b> Spurious regression</a></li>
</ul></li>
<li class="chapter" data-level="7.4" data-path="time-series-regression-models.html"><a href="time-series-regression-models.html#some-useful-predictors"><i class="fa fa-check"></i><b>7.4</b> Some useful predictors</a><ul>
<li class="chapter" data-level="7.4.1" data-path="time-series-regression-models.html"><a href="time-series-regression-models.html#trend"><i class="fa fa-check"></i><b>7.4.1</b> Trend</a></li>
<li class="chapter" data-level="7.4.2" data-path="time-series-regression-models.html"><a href="time-series-regression-models.html#seasonal-dummy-variables"><i class="fa fa-check"></i><b>7.4.2</b> Seasonal dummy variables</a></li>
<li class="chapter" data-level="7.4.3" data-path="time-series-regression-models.html"><a href="time-series-regression-models.html#example-australian-quarterly-beer-production"><i class="fa fa-check"></i><b>7.4.3</b> Example: Australian quarterly beer production</a></li>
<li class="chapter" data-level="7.4.4" data-path="time-series-regression-models.html"><a href="time-series-regression-models.html#intervention-variables"><i class="fa fa-check"></i><b>7.4.4</b> Intervention variables</a></li>
<li class="chapter" data-level="7.4.5" data-path="time-series-regression-models.html"><a href="time-series-regression-models.html#trading-days"><i class="fa fa-check"></i><b>7.4.5</b> Trading days</a></li>
<li class="chapter" data-level="7.4.6" data-path="time-series-regression-models.html"><a href="time-series-regression-models.html#distributed-lags"><i class="fa fa-check"></i><b>7.4.6</b> Distributed lags</a></li>
<li class="chapter" data-level="7.4.7" data-path="time-series-regression-models.html"><a href="time-series-regression-models.html#easter"><i class="fa fa-check"></i><b>7.4.7</b> Easter</a></li>
<li class="chapter" data-level="7.4.8" data-path="time-series-regression-models.html"><a href="time-series-regression-models.html#fourier-sereis"><i class="fa fa-check"></i><b>7.4.8</b> Fourier sereis</a></li>
</ul></li>
<li class="chapter" data-level="7.5" data-path="time-series-regression-models.html"><a href="time-series-regression-models.html#selecting-predictors"><i class="fa fa-check"></i><b>7.5</b> Selecting predictors</a><ul>
<li class="chapter" data-level="7.5.1" data-path="time-series-regression-models.html"><a href="time-series-regression-models.html#adjusst-r-square"><i class="fa fa-check"></i><b>7.5.1</b> Adjusst R square</a></li>
<li class="chapter" data-level="7.5.2" data-path="time-series-regression-models.html"><a href="time-series-regression-models.html#cross-validation"><i class="fa fa-check"></i><b>7.5.2</b> Cross validation</a></li>
<li class="chapter" data-level="7.5.3" data-path="time-series-regression-models.html"><a href="time-series-regression-models.html#akaikes-information-criterion"><i class="fa fa-check"></i><b>7.5.3</b> Akaike’s Information Criterion</a></li>
<li class="chapter" data-level="7.5.4" data-path="time-series-regression-models.html"><a href="time-series-regression-models.html#bayesian-information-criterion"><i class="fa fa-check"></i><b>7.5.4</b> Bayesian Information Criterion</a></li>
<li class="chapter" data-level="7.5.5" data-path="time-series-regression-models.html"><a href="time-series-regression-models.html#which-measure-should-we-suse"><i class="fa fa-check"></i><b>7.5.5</b> Which measure should we suse</a></li>
<li class="chapter" data-level="7.5.6" data-path="time-series-regression-models.html"><a href="time-series-regression-models.html#example-us-consumption"><i class="fa fa-check"></i><b>7.5.6</b> Example: US consumption</a></li>
</ul></li>
<li class="chapter" data-level="7.6" data-path="time-series-regression-models.html"><a href="time-series-regression-models.html#forecasting-with-regression"><i class="fa fa-check"></i><b>7.6</b> Forecasting with regression</a><ul>
<li class="chapter" data-level="7.6.1" data-path="time-series-regression-models.html"><a href="time-series-regression-models.html#ex-ante-versus-ex-post-forecasts"><i class="fa fa-check"></i><b>7.6.1</b> Ex-ante versus ex-post forecasts</a></li>
<li class="chapter" data-level="7.6.2" data-path="time-series-regression-models.html"><a href="time-series-regression-models.html#example-australian-quarterly-beer-production-1"><i class="fa fa-check"></i><b>7.6.2</b> Example: Australian quarterly beer production</a></li>
<li class="chapter" data-level="7.6.3" data-path="time-series-regression-models.html"><a href="time-series-regression-models.html#scenario-based-forecasting"><i class="fa fa-check"></i><b>7.6.3</b> Scenario based forecasting</a></li>
<li class="chapter" data-level="7.6.4" data-path="time-series-regression-models.html"><a href="time-series-regression-models.html#prediction-intervals"><i class="fa fa-check"></i><b>7.6.4</b> Prediction intervals</a></li>
<li class="chapter" data-level="7.6.5" data-path="time-series-regression-models.html"><a href="time-series-regression-models.html#building-a-predictive-regression-model"><i class="fa fa-check"></i><b>7.6.5</b> Building a predictive regression model</a></li>
</ul></li>
<li class="chapter" data-level="7.7" data-path="time-series-regression-models.html"><a href="time-series-regression-models.html#matrix-formulation"><i class="fa fa-check"></i><b>7.7</b> Matrix formulation</a></li>
<li class="chapter" data-level="7.8" data-path="time-series-regression-models.html"><a href="time-series-regression-models.html#nonlinear-regression"><i class="fa fa-check"></i><b>7.8</b> Nonlinear regression</a><ul>
<li class="chapter" data-level="7.8.1" data-path="time-series-regression-models.html"><a href="time-series-regression-models.html#forecasting-with-a-nonlinear-trend"><i class="fa fa-check"></i><b>7.8.1</b> Forecasting with a nonlinear trend</a></li>
<li class="chapter" data-level="7.8.2" data-path="time-series-regression-models.html"><a href="time-series-regression-models.html#example-boston-marathon-winning-times"><i class="fa fa-check"></i><b>7.8.2</b> Example: Boston marathon winning times</a></li>
</ul></li>
<li class="chapter" data-level="7.9" data-path="time-series-regression-models.html"><a href="time-series-regression-models.html#correlation-causation-and-forecasting"><i class="fa fa-check"></i><b>7.9</b> Correlation, causation and forecasting</a></li>
</ul></li>
<li class="chapter" data-level="8" data-path="exponential-smoothing.html"><a href="exponential-smoothing.html"><i class="fa fa-check"></i><b>8</b> Exponential smoothing</a><ul>
<li class="chapter" data-level="8.1" data-path="exponential-smoothing.html"><a href="exponential-smoothing.html#simple-exponential-smoothing"><i class="fa fa-check"></i><b>8.1</b> Simple exponential smoothing</a><ul>
<li class="chapter" data-level="8.1.1" data-path="exponential-smoothing.html"><a href="exponential-smoothing.html#weighted-average-form"><i class="fa fa-check"></i><b>8.1.1</b> Weighted average form</a></li>
<li class="chapter" data-level="8.1.2" data-path="exponential-smoothing.html"><a href="exponential-smoothing.html#component-form"><i class="fa fa-check"></i><b>8.1.2</b> Component form</a></li>
<li class="chapter" data-level="8.1.3" data-path="exponential-smoothing.html"><a href="exponential-smoothing.html#flat-forecast"><i class="fa fa-check"></i><b>8.1.3</b> Flat forecast</a></li>
<li class="chapter" data-level="8.1.4" data-path="exponential-smoothing.html"><a href="exponential-smoothing.html#estimation"><i class="fa fa-check"></i><b>8.1.4</b> Estimation</a></li>
<li class="chapter" data-level="8.1.5" data-path="exponential-smoothing.html"><a href="exponential-smoothing.html#example-algerian-exports"><i class="fa fa-check"></i><b>8.1.5</b> Example: Algerian exports</a></li>
</ul></li>
<li class="chapter" data-level="8.2" data-path="exponential-smoothing.html"><a href="exponential-smoothing.html#methods-with-trend-and-seasonality"><i class="fa fa-check"></i><b>8.2</b> Methods with trend and seasonality</a><ul>
<li class="chapter" data-level="8.2.1" data-path="exponential-smoothing.html"><a href="exponential-smoothing.html#holts-linear-trend-method"><i class="fa fa-check"></i><b>8.2.1</b> Holt’s linear trend method</a></li>
<li class="chapter" data-level="8.2.2" data-path="exponential-smoothing.html"><a href="exponential-smoothing.html#example-australian-population"><i class="fa fa-check"></i><b>8.2.2</b> Example: Australian population</a></li>
<li class="chapter" data-level="8.2.3" data-path="exponential-smoothing.html"><a href="exponential-smoothing.html#damped-trend-methods"><i class="fa fa-check"></i><b>8.2.3</b> Damped trend methods</a></li>
<li class="chapter" data-level="8.2.4" data-path="exponential-smoothing.html"><a href="exponential-smoothing.html#example-australian-population-continued"><i class="fa fa-check"></i><b>8.2.4</b> Example: Australian Population (continued)</a></li>
<li class="chapter" data-level="8.2.5" data-path="exponential-smoothing.html"><a href="exponential-smoothing.html#example-internet-usage"><i class="fa fa-check"></i><b>8.2.5</b> Example: Internet usage</a></li>
<li class="chapter" data-level="8.2.6" data-path="exponential-smoothing.html"><a href="exponential-smoothing.html#holt-winters-additive-method"><i class="fa fa-check"></i><b>8.2.6</b> Holt-Winters’ additive method</a></li>
<li class="chapter" data-level="8.2.7" data-path="exponential-smoothing.html"><a href="exponential-smoothing.html#holt-winters-multiplicative-method"><i class="fa fa-check"></i><b>8.2.7</b> Holt-Winters’ multiplicative method</a></li>
<li class="chapter" data-level="8.2.8" data-path="exponential-smoothing.html"><a href="exponential-smoothing.html#example-domestic-overnight-trips-in-australia"><i class="fa fa-check"></i><b>8.2.8</b> Example: Domestic overnight trips in Australia</a></li>
<li class="chapter" data-level="8.2.9" data-path="exponential-smoothing.html"><a href="exponential-smoothing.html#holt-winters-damped-method"><i class="fa fa-check"></i><b>8.2.9</b> Holt-Winters’ damped method</a></li>
<li class="chapter" data-level="8.2.10" data-path="exponential-smoothing.html"><a href="exponential-smoothing.html#example-holt-winters-method-with-daily-data"><i class="fa fa-check"></i><b>8.2.10</b> Example: Holt-Winters method with daily data</a></li>
</ul></li>
<li class="chapter" data-level="8.3" data-path="exponential-smoothing.html"><a href="exponential-smoothing.html#a-taxonomy-of-exponential-smoothing-methods"><i class="fa fa-check"></i><b>8.3</b> A taxonomy of exponential smoothing methods</a></li>
<li class="chapter" data-level="8.4" data-path="exponential-smoothing.html"><a href="exponential-smoothing.html#innovations-state-space-models-for-exponential-smoothing"><i class="fa fa-check"></i><b>8.4</b> Innovations state space models for exponential smoothing</a><ul>
<li class="chapter" data-level="8.4.1" data-path="exponential-smoothing.html"><a href="exponential-smoothing.html#etsann-simple-exponential-smoothing-with-additive-errors"><i class="fa fa-check"></i><b>8.4.1</b> ETS(A,N,N): simple exponential smoothing with additive errors</a></li>
<li class="chapter" data-level="8.4.2" data-path="exponential-smoothing.html"><a href="exponential-smoothing.html#etsmnn-simple-exponential-smoothing-with-multiplicative-errors"><i class="fa fa-check"></i><b>8.4.2</b> ETS(M,N,N): simple exponential smoothing with multiplicative errors</a></li>
<li class="chapter" data-level="8.4.3" data-path="exponential-smoothing.html"><a href="exponential-smoothing.html#etsaan-holts-linear-method-with-additive-errors"><i class="fa fa-check"></i><b>8.4.3</b> ETS(A,A,N): Holt’s linear method with additive errors</a></li>
<li class="chapter" data-level="8.4.4" data-path="exponential-smoothing.html"><a href="exponential-smoothing.html#ets-man"><i class="fa fa-check"></i><b>8.4.4</b> ETS(M,A,N): Holt’s linear method with multiplicative errors</a></li>
<li class="chapter" data-level="8.4.5" data-path="exponential-smoothing.html"><a href="exponential-smoothing.html#other-ets-models"><i class="fa fa-check"></i><b>8.4.5</b> Other ETS models</a></li>
</ul></li>
<li class="chapter" data-level="8.5" data-path="exponential-smoothing.html"><a href="exponential-smoothing.html#estimation-and-model-selection"><i class="fa fa-check"></i><b>8.5</b> Estimation and model selection</a><ul>
<li class="chapter" data-level="8.5.1" data-path="exponential-smoothing.html"><a href="exponential-smoothing.html#estimating-ets-models"><i class="fa fa-check"></i><b>8.5.1</b> Estimating ETS models</a></li>
<li class="chapter" data-level="8.5.2" data-path="exponential-smoothing.html"><a href="exponential-smoothing.html#model-selection-criteria"><i class="fa fa-check"></i><b>8.5.2</b> Model selection criteria</a></li>
<li class="chapter" data-level="8.5.3" data-path="exponential-smoothing.html"><a href="exponential-smoothing.html#example-domestic-holiday-tourist-visitor-nights-in-australia"><i class="fa fa-check"></i><b>8.5.3</b> Example: Domestic holiday tourist visitor nights in Australia</a></li>
</ul></li>
<li class="chapter" data-level="8.6" data-path="exponential-smoothing.html"><a href="exponential-smoothing.html#forecasting-with-ets-models"><i class="fa fa-check"></i><b>8.6</b> Forecasting with ETS models</a><ul>
<li class="chapter" data-level="8.6.1" data-path="exponential-smoothing.html"><a href="exponential-smoothing.html#example-australia-gas-production"><i class="fa fa-check"></i><b>8.6.1</b> Example: Australia gas production</a></li>
<li class="chapter" data-level="8.6.2" data-path="time-series-regression-models.html"><a href="time-series-regression-models.html#prediction-intervals"><i class="fa fa-check"></i><b>8.6.2</b> Prediction intervals</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="9" data-path="univariate-stationary-processes.html"><a href="univariate-stationary-processes.html"><i class="fa fa-check"></i><b>9</b> Univariate stationary processes</a><ul>
<li class="chapter" data-level="9.1" data-path="univariate-stationary-processes.html"><a href="univariate-stationary-processes.html#stationarity"><i class="fa fa-check"></i><b>9.1</b> Stationarity</a><ul>
<li class="chapter" data-level="9.1.1" data-path="univariate-stationary-processes.html"><a href="univariate-stationary-processes.html#ch9-white-noise"><i class="fa fa-check"></i><b>9.1.1</b> White noise</a></li>
<li class="chapter" data-level="9.1.2" data-path="univariate-stationary-processes.html"><a href="univariate-stationary-processes.html#tests-for-autocorrelation-and-normality"><i class="fa fa-check"></i><b>9.1.2</b> Tests for autocorrelation and normality</a></li>
<li class="chapter" data-level="9.1.3" data-path="univariate-stationary-processes.html"><a href="univariate-stationary-processes.html#the-wold-decomposition"><i class="fa fa-check"></i><b>9.1.3</b> The Wold Decomposition</a></li>
</ul></li>
<li class="chapter" data-level="9.2" data-path="univariate-stationary-processes.html"><a href="univariate-stationary-processes.html#backshift-notation"><i class="fa fa-check"></i><b>9.2</b> Backshift notation</a></li>
<li class="chapter" data-level="9.3" data-path="univariate-stationary-processes.html"><a href="univariate-stationary-processes.html#autoregressive-models"><i class="fa fa-check"></i><b>9.3</b> Autoregressive models</a><ul>
<li class="chapter" data-level="9.3.1" data-path="univariate-stationary-processes.html"><a href="univariate-stationary-processes.html#stimulating-an-arp-process"><i class="fa fa-check"></i><b>9.3.1</b> Stimulating an AR(p) process</a></li>
<li class="chapter" data-level="9.3.2" data-path="univariate-stationary-processes.html"><a href="univariate-stationary-processes.html#decision-of-order-p"><i class="fa fa-check"></i><b>9.3.2</b> Decision of order p</a></li>
<li class="chapter" data-level="9.3.3" data-path="univariate-stationary-processes.html"><a href="univariate-stationary-processes.html#random-walk"><i class="fa fa-check"></i><b>9.3.3</b> Random walk</a></li>
</ul></li>
<li class="chapter" data-level="9.4" data-path="univariate-stationary-processes.html"><a href="univariate-stationary-processes.html#moving-average-models"><i class="fa fa-check"></i><b>9.4</b> Moving average models</a><ul>
<li class="chapter" data-level="9.4.1" data-path="univariate-stationary-processes.html"><a href="univariate-stationary-processes.html#simulating-an-maq-process"><i class="fa fa-check"></i><b>9.4.1</b> Simulating an MA(q) process</a></li>
<li class="chapter" data-level="9.4.2" data-path="univariate-stationary-processes.html"><a href="univariate-stationary-processes.html#decision-of-order-q"><i class="fa fa-check"></i><b>9.4.2</b> Decision of order q</a></li>
<li class="chapter" data-level="9.4.3" data-path="univariate-stationary-processes.html"><a href="univariate-stationary-processes.html#koyck-transformation-and-invertibility"><i class="fa fa-check"></i><b>9.4.3</b> Koyck transformation and Invertibility</a></li>
</ul></li>
<li class="chapter" data-level="9.5" data-path="univariate-stationary-processes.html"><a href="univariate-stationary-processes.html#arma-models"><i class="fa fa-check"></i><b>9.5</b> ARMA models</a><ul>
<li class="chapter" data-level="9.5.1" data-path="univariate-stationary-processes.html"><a href="univariate-stationary-processes.html#three-representations-of-an-arma-model"><i class="fa fa-check"></i><b>9.5.1</b> Three representations of an ARMA model</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="10" data-path="arima-models.html"><a href="arima-models.html"><i class="fa fa-check"></i><b>10</b> ARIMA models</a><ul>
<li class="chapter" data-level="10.1" data-path="arima-models.html"><a href="arima-models.html#differencing"><i class="fa fa-check"></i><b>10.1</b> Differencing</a><ul>
<li class="chapter" data-level="10.1.1" data-path="arima-models.html"><a href="arima-models.html#second-order-differencing"><i class="fa fa-check"></i><b>10.1.1</b> Second-order differencing</a></li>
<li class="chapter" data-level="10.1.2" data-path="arima-models.html"><a href="arima-models.html#seasonal-differencing"><i class="fa fa-check"></i><b>10.1.2</b> Seasonal differencing</a></li>
<li class="chapter" data-level="10.1.3" data-path="arima-models.html"><a href="arima-models.html#unit-root-tests"><i class="fa fa-check"></i><b>10.1.3</b> Unit root tests</a></li>
</ul></li>
<li class="chapter" data-level="10.2" data-path="arima-models.html"><a href="arima-models.html#non-seasonal-arima-models"><i class="fa fa-check"></i><b>10.2</b> Non-seasonal ARIMA models</a><ul>
<li class="chapter" data-level="10.2.1" data-path="arima-models.html"><a href="arima-models.html#understanding-arima-models"><i class="fa fa-check"></i><b>10.2.1</b> Understanding ARIMA models</a></li>
</ul></li>
<li class="chapter" data-level="10.3" data-path="arima-models.html"><a href="arima-models.html#estimation-and-order-selection"><i class="fa fa-check"></i><b>10.3</b> Estimation and order selection</a><ul>
<li class="chapter" data-level="10.3.1" data-path="arima-models.html"><a href="arima-models.html#mle"><i class="fa fa-check"></i><b>10.3.1</b> MLE</a></li>
<li class="chapter" data-level="10.3.2" data-path="arima-models.html"><a href="arima-models.html#information-criteria"><i class="fa fa-check"></i><b>10.3.2</b> Information Criteria</a></li>
</ul></li>
<li class="chapter" data-level="10.4" data-path="arima-models.html"><a href="arima-models.html#the-arima-function"><i class="fa fa-check"></i><b>10.4</b> The <code>ARIMA()</code> function</a><ul>
<li class="chapter" data-level="10.4.1" data-path="arima-models.html"><a href="arima-models.html#algorithm"><i class="fa fa-check"></i><b>10.4.1</b> Algorithm</a></li>
<li class="chapter" data-level="10.4.2" data-path="arima-models.html"><a href="arima-models.html#modelling-procedure"><i class="fa fa-check"></i><b>10.4.2</b> Modelling procedure</a></li>
<li class="chapter" data-level="10.4.3" data-path="arima-models.html"><a href="arima-models.html#example-seasonally-adjusted-electrical-equipment-orders"><i class="fa fa-check"></i><b>10.4.3</b> Example: Seasonally adjusted electrical equipment orders</a></li>
<li class="chapter" data-level="10.4.4" data-path="arima-models.html"><a href="arima-models.html#plotting-the-characteristic-roots"><i class="fa fa-check"></i><b>10.4.4</b> Plotting the characteristic roots</a></li>
</ul></li>
<li class="chapter" data-level="10.5" data-path="arima-models.html"><a href="arima-models.html#forecasting-with-arima-models"><i class="fa fa-check"></i><b>10.5</b> Forecasting with ARIMA models</a><ul>
<li class="chapter" data-level="10.5.1" data-path="arima-models.html"><a href="arima-models.html#point-forecasts"><i class="fa fa-check"></i><b>10.5.1</b> Point forecasts</a></li>
<li class="chapter" data-level="10.5.2" data-path="time-series-regression-models.html"><a href="time-series-regression-models.html#prediction-intervals"><i class="fa fa-check"></i><b>10.5.2</b> Prediction intervals</a></li>
</ul></li>
<li class="chapter" data-level="10.6" data-path="arima-models.html"><a href="arima-models.html#seasonal-arima-models"><i class="fa fa-check"></i><b>10.6</b> Seasonal ARIMA models</a><ul>
<li class="chapter" data-level="10.6.1" data-path="arima-models.html"><a href="arima-models.html#acf-and-pacf"><i class="fa fa-check"></i><b>10.6.1</b> ACF and PACF</a></li>
<li class="chapter" data-level="10.6.2" data-path="arima-models.html"><a href="arima-models.html#example-european-quarterly-retail-trade"><i class="fa fa-check"></i><b>10.6.2</b> Example: European quarterly retail trade</a></li>
<li class="chapter" data-level="10.6.3" data-path="arima-models.html"><a href="arima-models.html#example-corticosteroid-drug-sales-in-australia"><i class="fa fa-check"></i><b>10.6.3</b> Example: Corticosteroid drug sales in Australia</a></li>
</ul></li>
<li class="chapter" data-level="10.7" data-path="arima-models.html"><a href="arima-models.html#ets-and-arima"><i class="fa fa-check"></i><b>10.7</b> ETS and ARIMA</a><ul>
<li class="chapter" data-level="10.7.1" data-path="arima-models.html"><a href="arima-models.html#example-comparing-arima-and-ets-on-non-seasonal-data"><i class="fa fa-check"></i><b>10.7.1</b> Example: Comparing <code>ARIMA()</code> and <code>ETS()</code> on non-seasonal data</a></li>
<li class="chapter" data-level="10.7.2" data-path="arima-models.html"><a href="arima-models.html#example-comparing-arima-and-ets-on-seasonal-data"><i class="fa fa-check"></i><b>10.7.2</b> Example: Comparing <code>ARIMA()</code> and <code>ETS()</code> on seasonal data</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="11" data-path="dynamic-regression-models.html"><a href="dynamic-regression-models.html"><i class="fa fa-check"></i><b>11</b> Dynamic regression models</a><ul>
<li class="chapter" data-level="11.1" data-path="exponential-smoothing.html"><a href="exponential-smoothing.html#estimation"><i class="fa fa-check"></i><b>11.1</b> Estimation</a></li>
<li class="chapter" data-level="11.2" data-path="dynamic-regression-models.html"><a href="dynamic-regression-models.html#regression-with-arima-errors"><i class="fa fa-check"></i><b>11.2</b> Regression with ARIMA errors</a><ul>
<li class="chapter" data-level="11.2.1" data-path="dynamic-regression-models.html"><a href="dynamic-regression-models.html#example-us-personal-consumption-and-income"><i class="fa fa-check"></i><b>11.2.1</b> Example: US Personal Consumption and Income</a></li>
</ul></li>
<li class="chapter" data-level="11.3" data-path="dynamic-regression-models.html"><a href="dynamic-regression-models.html#forecasting"><i class="fa fa-check"></i><b>11.3</b> Forecasting</a><ul>
<li class="chapter" data-level="11.3.1" data-path="dynamic-regression-models.html"><a href="dynamic-regression-models.html#example-forecasting-electricity-demand"><i class="fa fa-check"></i><b>11.3.1</b> Example: Forecasting electricity demand</a></li>
</ul></li>
<li class="chapter" data-level="11.4" data-path="dynamic-regression-models.html"><a href="dynamic-regression-models.html#deterministic-and-stochastic-trends"><i class="fa fa-check"></i><b>11.4</b> Deterministic and stochastic trends</a><ul>
<li class="chapter" data-level="11.4.1" data-path="dynamic-regression-models.html"><a href="dynamic-regression-models.html#example-international-visitors-to-australia"><i class="fa fa-check"></i><b>11.4.1</b> Example: International visitors to Australia</a></li>
</ul></li>
<li class="chapter" data-level="11.5" data-path="dynamic-regression-models.html"><a href="dynamic-regression-models.html#dynamic-harmonic-regression"><i class="fa fa-check"></i><b>11.5</b> Dynamic harmonic regression</a><ul>
<li class="chapter" data-level="11.5.1" data-path="dynamic-regression-models.html"><a href="dynamic-regression-models.html#example-australian-eating-out-expenditure"><i class="fa fa-check"></i><b>11.5.1</b> Example: Australian eating out expenditure</a></li>
</ul></li>
<li class="chapter" data-level="11.6" data-path="dynamic-regression-models.html"><a href="dynamic-regression-models.html#lagged-predictors"><i class="fa fa-check"></i><b>11.6</b> Lagged predictors</a><ul>
<li class="chapter" data-level="11.6.1" data-path="dynamic-regression-models.html"><a href="dynamic-regression-models.html#example-tv-advertising-and-insurance-quotations"><i class="fa fa-check"></i><b>11.6.1</b> Example: TV advertising and insurance quotations</a></li>
</ul></li>
</ul></li>
<li class="chapter" data-level="" data-path="references.html"><a href="references.html"><i class="fa fa-check"></i>References</a></li>
<li class="divider"></li>
<li><a href="https://github.com/rstudio/bookdown" target="blank">written with bookdown</a></li>

</ul>

      </nav>
    </div>

    <div class="book-body">
      <div class="body-inner">
        <div class="book-header" role="navigation">
          <h1>
            <i class="fa fa-circle-o-notch fa-spin"></i><a href="./">Notes for “Forecasting: Principles and Practice, 3rd edition”</a>
          </h1>
        </div>

        <div class="page-wrapper" tabindex="-1" role="main">
          <div class="page-inner">

            <section class="normal" id="section-">
<div id="time-series-regression-models" class="section level1">
<h1><span class="header-section-number">Chapter 7</span> Time series regression models</h1>
<div class="sourceCode" id="cb110"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb110-1"><a href="time-series-regression-models.html#cb110-1"></a><span class="kw">library</span>(tsibble)</span>
<span id="cb110-2"><a href="time-series-regression-models.html#cb110-2"></a><span class="kw">library</span>(tsibbledata)</span>
<span id="cb110-3"><a href="time-series-regression-models.html#cb110-3"></a><span class="kw">library</span>(fable)</span>
<span id="cb110-4"><a href="time-series-regression-models.html#cb110-4"></a><span class="kw">library</span>(feasts)</span>
<span id="cb110-5"><a href="time-series-regression-models.html#cb110-5"></a><span class="kw">library</span>(lubridate)</span>
<span id="cb110-6"><a href="time-series-regression-models.html#cb110-6"></a><span class="kw">library</span>(patchwork)</span></code></pre></div>
<p>In this chapter we discuss regression models. The basic concept is that we forecast the time series of interest y assuming that it has a linear relationship with other time series <span class="math inline">\(x\)</span>.</p>
<p>For example, we might wish to forecast monthly sales <span class="math inline">\(y\)</span>
using total advertising spend <span class="math inline">\(x\)</span> as a predictor. Or we might forecast daily electricity demand <span class="math inline">\(y\)</span> using temperature <span class="math inline">\(x_1\)</span> and the day of week <span class="math inline">\(x_2\)</span> as predictors.</p>
<div id="the-linear-model" class="section level2">
<h2><span class="header-section-number">7.1</span> The linear model</h2>
<div id="simple-linear-regression" class="section level3">
<h3><span class="header-section-number">7.1.1</span> Simple linear regression</h3>
<p>In the simplest case, the regression model allows for a linear relationship between the forecast variable <span class="math inline">\(y\)</span> and a single predictor variable <span class="math inline">\(x\)</span>:</p>
<p><span class="math display">\[
y_t = \beta_0 + \beta_1x_t + \varepsilon_t
\]</span></p>
<p>Use the US consumption data, <code>us_change</code>, to fit a simple linear model where <code>Consumption</code> is predicted against <code>Income</code>. First, plot these two time series</p>
<div class="sourceCode" id="cb111"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb111-1"><a href="time-series-regression-models.html#cb111-1"></a>us_change &lt;-<span class="st"> </span>fpp3<span class="op">::</span>us_change</span>
<span id="cb111-2"><a href="time-series-regression-models.html#cb111-2"></a></span>
<span id="cb111-3"><a href="time-series-regression-models.html#cb111-3"></a>us_change <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb111-4"><a href="time-series-regression-models.html#cb111-4"></a><span class="st">  </span><span class="kw">pivot_longer</span>(<span class="kw">c</span>(Consumption, Income)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb111-5"><a href="time-series-regression-models.html#cb111-5"></a><span class="st">  </span><span class="kw">ggplot</span>() <span class="op">+</span><span class="st"> </span></span>
<span id="cb111-6"><a href="time-series-regression-models.html#cb111-6"></a><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(Quarter, value, <span class="dt">color =</span> name)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb111-7"><a href="time-series-regression-models.html#cb111-7"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">y =</span> <span class="st">&quot;% change&quot;</span>,</span>
<span id="cb111-8"><a href="time-series-regression-models.html#cb111-8"></a>       <span class="dt">color =</span> <span class="st">&quot;Series&quot;</span>)</span></code></pre></div>
<p><img src="ch7_files/figure-html/unnamed-chunk-4-1.png" width="100%" style="display: block; margin: auto;" /></p>
<p>And then make a scatter plot:</p>
<div class="sourceCode" id="cb112"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb112-1"><a href="time-series-regression-models.html#cb112-1"></a>us_change <span class="op">%&gt;%</span></span>
<span id="cb112-2"><a href="time-series-regression-models.html#cb112-2"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(Income, Consumption)) <span class="op">+</span></span>
<span id="cb112-3"><a href="time-series-regression-models.html#cb112-3"></a><span class="st">    </span><span class="kw">ylab</span>(<span class="st">&quot;Consumption (quarterly % change)&quot;</span>) <span class="op">+</span></span>
<span id="cb112-4"><a href="time-series-regression-models.html#cb112-4"></a><span class="st">    </span><span class="kw">xlab</span>(<span class="st">&quot;Income (quarterly % change)&quot;</span>) <span class="op">+</span></span>
<span id="cb112-5"><a href="time-series-regression-models.html#cb112-5"></a><span class="st">    </span><span class="kw">geom_point</span>() <span class="op">+</span></span>
<span id="cb112-6"><a href="time-series-regression-models.html#cb112-6"></a><span class="st">    </span><span class="kw">geom_smooth</span>(<span class="dt">method=</span><span class="st">&quot;lm&quot;</span>, <span class="dt">se=</span><span class="ot">FALSE</span>)</span></code></pre></div>
<p><img src="ch7_files/figure-html/unnamed-chunk-5-1.png" width="100%" style="display: block; margin: auto;" /></p>
<p>Fit a formal model:</p>
<div class="sourceCode" id="cb113"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb113-1"><a href="time-series-regression-models.html#cb113-1"></a>us_change_fit &lt;-<span class="st"> </span><span class="kw">lm</span>(Consumption <span class="op">~</span><span class="st"> </span>Income, <span class="dt">data =</span> us_change)</span>
<span id="cb113-2"><a href="time-series-regression-models.html#cb113-2"></a>us_change_fit <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">glance</span>()</span>
<span id="cb113-3"><a href="time-series-regression-models.html#cb113-3"></a><span class="co">#&gt; # A tibble: 1 x 12</span></span>
<span id="cb113-4"><a href="time-series-regression-models.html#cb113-4"></a><span class="co">#&gt;   r.squared adj.r.squared sigma statistic p.value    df logLik   AIC   BIC</span></span>
<span id="cb113-5"><a href="time-series-regression-models.html#cb113-5"></a><span class="co">#&gt;       &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;   &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;</span></span>
<span id="cb113-6"><a href="time-series-regression-models.html#cb113-6"></a><span class="co">#&gt; 1     0.147         0.143 0.591      33.8 2.40e-8     1  -176.  357.  367.</span></span>
<span id="cb113-7"><a href="time-series-regression-models.html#cb113-7"></a><span class="co">#&gt; # ... with 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;</span></span></code></pre></div>
<p>The simple linear model can be written as</p>
<p><span class="math display">\[
\operatorname{Consumption} = 0.54 + 0.27(\operatorname{Income}) + \epsilon
\]</span></p>
<p><code>TSLM()</code> (time series regression model) is more compatible with the modelling workflow in <code>fable</code>, compared to the general method <code>lm()</code></p>
<div class="sourceCode" id="cb114"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb114-1"><a href="time-series-regression-models.html#cb114-1"></a>us_change <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb114-2"><a href="time-series-regression-models.html#cb114-2"></a><span class="st">  </span><span class="kw">model</span>(<span class="kw">TSLM</span>(Consumption <span class="op">~</span><span class="st"> </span>Income)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb114-3"><a href="time-series-regression-models.html#cb114-3"></a><span class="st">  </span><span class="kw">report</span>()</span>
<span id="cb114-4"><a href="time-series-regression-models.html#cb114-4"></a><span class="co">#&gt; Series: Consumption </span></span>
<span id="cb114-5"><a href="time-series-regression-models.html#cb114-5"></a><span class="co">#&gt; Model: TSLM </span></span>
<span id="cb114-6"><a href="time-series-regression-models.html#cb114-6"></a><span class="co">#&gt; </span></span>
<span id="cb114-7"><a href="time-series-regression-models.html#cb114-7"></a><span class="co">#&gt; Residuals:</span></span>
<span id="cb114-8"><a href="time-series-regression-models.html#cb114-8"></a><span class="co">#&gt;      Min       1Q   Median       3Q      Max </span></span>
<span id="cb114-9"><a href="time-series-regression-models.html#cb114-9"></a><span class="co">#&gt; -2.58236 -0.27777  0.01862  0.32330  1.42229 </span></span>
<span id="cb114-10"><a href="time-series-regression-models.html#cb114-10"></a><span class="co">#&gt; </span></span>
<span id="cb114-11"><a href="time-series-regression-models.html#cb114-11"></a><span class="co">#&gt; Coefficients:</span></span>
<span id="cb114-12"><a href="time-series-regression-models.html#cb114-12"></a><span class="co">#&gt;             Estimate Std. Error t value Pr(&gt;|t|)    </span></span>
<span id="cb114-13"><a href="time-series-regression-models.html#cb114-13"></a><span class="co">#&gt; (Intercept)  0.54454    0.05403  10.079  &lt; 2e-16 ***</span></span>
<span id="cb114-14"><a href="time-series-regression-models.html#cb114-14"></a><span class="co">#&gt; Income       0.27183    0.04673   5.817  2.4e-08 ***</span></span>
<span id="cb114-15"><a href="time-series-regression-models.html#cb114-15"></a><span class="co">#&gt; ---</span></span>
<span id="cb114-16"><a href="time-series-regression-models.html#cb114-16"></a><span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></span>
<span id="cb114-17"><a href="time-series-regression-models.html#cb114-17"></a><span class="co">#&gt; </span></span>
<span id="cb114-18"><a href="time-series-regression-models.html#cb114-18"></a><span class="co">#&gt; Residual standard error: 0.5905 on 196 degrees of freedom</span></span>
<span id="cb114-19"><a href="time-series-regression-models.html#cb114-19"></a><span class="co">#&gt; Multiple R-squared: 0.1472,	Adjusted R-squared: 0.1429</span></span>
<span id="cb114-20"><a href="time-series-regression-models.html#cb114-20"></a><span class="co">#&gt; F-statistic: 33.84 on 1 and 196 DF, p-value: 2.4022e-08</span></span></code></pre></div>
<p><code>report()</code> displays a object in a suitable format for reporting, here its result is identical to <code>summary.lm()</code>. <code>TSLM()</code></p>
</div>
<div id="multiple-linear-regression" class="section level3">
<h3><span class="header-section-number">7.1.2</span> Multiple linear regression</h3>
<p><span class="math display" id="eq:multiple-linear-reg">\[\begin{equation}
\tag{7.1}
y_t = \beta_0 + \beta_1x_{1t} + \beta_2x_{2t} + \dots + \beta_kx_{kt} + \varepsilon_t
\end{equation}\]</span></p>
<p>We could simply use more predictors in <code>us_change</code> to create a multiple linear regression model. This time, the last 4 columns are included in the model. Take a look at the rest 3 time series determined by <code>Production</code>, <code>Savings</code> and <code>Unemployment</code></p>
<div class="sourceCode" id="cb115"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb115-1"><a href="time-series-regression-models.html#cb115-1"></a>us_change <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb115-2"><a href="time-series-regression-models.html#cb115-2"></a><span class="st">  </span><span class="kw">pivot_longer</span>(<span class="dv">4</span><span class="op">:</span><span class="dv">6</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb115-3"><a href="time-series-regression-models.html#cb115-3"></a><span class="st">  </span><span class="kw">ggplot</span>() <span class="op">+</span><span class="st"> </span></span>
<span id="cb115-4"><a href="time-series-regression-models.html#cb115-4"></a><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(Quarter, value, <span class="dt">color =</span> name)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb115-5"><a href="time-series-regression-models.html#cb115-5"></a><span class="st">  </span><span class="kw">facet_wrap</span>(<span class="kw">vars</span>(name), <span class="dt">nrow =</span> <span class="dv">3</span>, <span class="dt">scales =</span> <span class="st">&quot;free_y&quot;</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb115-6"><a href="time-series-regression-models.html#cb115-6"></a><span class="st">  </span><span class="kw">scale_color_discrete</span>(<span class="dt">guide =</span> <span class="ot">FALSE</span>)</span></code></pre></div>
<p><img src="ch7_files/figure-html/unnamed-chunk-9-1.png" width="100%" style="display: block; margin: auto;" /></p>
<p>Below is a scatterplot matrix of five variables. The first column shows the relationships between the forecast variable (<code>consumption</code>) and each of the predictors. The scatterplots show positive relationships with income and industrial production, and negative relationships with savings and unemployment.</p>
<div class="sourceCode" id="cb116"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb116-1"><a href="time-series-regression-models.html#cb116-1"></a>GGally<span class="op">::</span><span class="kw">ggpairs</span>(us_change[, <span class="dv">2</span><span class="op">:</span><span class="dv">6</span>])</span></code></pre></div>
<div class="figure" style="text-align: center"><span id="fig:pairs"></span>
<img src="ch7_files/figure-html/pairs-1.png" alt="A scatterplot matrix of all 5 variables" width="100%" />
<p class="caption">
Figure 7.1: A scatterplot matrix of all 5 variables
</p>
</div>
<p>There may some concerns about multicolinearity, but VIF (Variance Inflation Factor) shows there is nothing to worry about:</p>
<div class="sourceCode" id="cb117"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb117-1"><a href="time-series-regression-models.html#cb117-1"></a><span class="kw">lm</span>(Consumption <span class="op">~</span><span class="st"> </span>Income <span class="op">+</span><span class="st"> </span>Production <span class="op">+</span><span class="st"> </span>Savings <span class="op">+</span><span class="st"> </span>Unemployment, </span>
<span id="cb117-2"><a href="time-series-regression-models.html#cb117-2"></a>   <span class="dt">data =</span> us_change) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb117-3"><a href="time-series-regression-models.html#cb117-3"></a><span class="st">   </span>car<span class="op">::</span><span class="kw">vif</span>()</span>
<span id="cb117-4"><a href="time-series-regression-models.html#cb117-4"></a><span class="co">#&gt;       Income   Production      Savings Unemployment </span></span>
<span id="cb117-5"><a href="time-series-regression-models.html#cb117-5"></a><span class="co">#&gt;     2.670685     2.537494     2.506434     2.519616</span></span></code></pre></div>
<p>Fit a multiple linear model:</p>
<div class="sourceCode" id="cb118"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb118-1"><a href="time-series-regression-models.html#cb118-1"></a>us_change_mfit &lt;-<span class="st"> </span>us_change <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb118-2"><a href="time-series-regression-models.html#cb118-2"></a><span class="st">  </span><span class="kw">model</span>(<span class="kw">TSLM</span>(Consumption <span class="op">~</span><span class="st"> </span>Income <span class="op">+</span><span class="st"> </span>Production <span class="op">+</span><span class="st"> </span>Savings <span class="op">+</span><span class="st"> </span>Unemployment))</span>
<span id="cb118-3"><a href="time-series-regression-models.html#cb118-3"></a></span>
<span id="cb118-4"><a href="time-series-regression-models.html#cb118-4"></a>us_change_mfit <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">report</span>()</span>
<span id="cb118-5"><a href="time-series-regression-models.html#cb118-5"></a><span class="co">#&gt; Series: Consumption </span></span>
<span id="cb118-6"><a href="time-series-regression-models.html#cb118-6"></a><span class="co">#&gt; Model: TSLM </span></span>
<span id="cb118-7"><a href="time-series-regression-models.html#cb118-7"></a><span class="co">#&gt; </span></span>
<span id="cb118-8"><a href="time-series-regression-models.html#cb118-8"></a><span class="co">#&gt; Residuals:</span></span>
<span id="cb118-9"><a href="time-series-regression-models.html#cb118-9"></a><span class="co">#&gt;      Min       1Q   Median       3Q      Max </span></span>
<span id="cb118-10"><a href="time-series-regression-models.html#cb118-10"></a><span class="co">#&gt; -0.90555 -0.15821 -0.03608  0.13618  1.15471 </span></span>
<span id="cb118-11"><a href="time-series-regression-models.html#cb118-11"></a><span class="co">#&gt; </span></span>
<span id="cb118-12"><a href="time-series-regression-models.html#cb118-12"></a><span class="co">#&gt; Coefficients:</span></span>
<span id="cb118-13"><a href="time-series-regression-models.html#cb118-13"></a><span class="co">#&gt;               Estimate Std. Error t value Pr(&gt;|t|)    </span></span>
<span id="cb118-14"><a href="time-series-regression-models.html#cb118-14"></a><span class="co">#&gt; (Intercept)   0.253105   0.034470   7.343 5.71e-12 ***</span></span>
<span id="cb118-15"><a href="time-series-regression-models.html#cb118-15"></a><span class="co">#&gt; Income        0.740583   0.040115  18.461  &lt; 2e-16 ***</span></span>
<span id="cb118-16"><a href="time-series-regression-models.html#cb118-16"></a><span class="co">#&gt; Production    0.047173   0.023142   2.038   0.0429 *  </span></span>
<span id="cb118-17"><a href="time-series-regression-models.html#cb118-17"></a><span class="co">#&gt; Savings      -0.052890   0.002924 -18.088  &lt; 2e-16 ***</span></span>
<span id="cb118-18"><a href="time-series-regression-models.html#cb118-18"></a><span class="co">#&gt; Unemployment -0.174685   0.095511  -1.829   0.0689 .  </span></span>
<span id="cb118-19"><a href="time-series-regression-models.html#cb118-19"></a><span class="co">#&gt; ---</span></span>
<span id="cb118-20"><a href="time-series-regression-models.html#cb118-20"></a><span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></span>
<span id="cb118-21"><a href="time-series-regression-models.html#cb118-21"></a><span class="co">#&gt; </span></span>
<span id="cb118-22"><a href="time-series-regression-models.html#cb118-22"></a><span class="co">#&gt; Residual standard error: 0.3102 on 193 degrees of freedom</span></span>
<span id="cb118-23"><a href="time-series-regression-models.html#cb118-23"></a><span class="co">#&gt; Multiple R-squared: 0.7683,	Adjusted R-squared: 0.7635</span></span>
<span id="cb118-24"><a href="time-series-regression-models.html#cb118-24"></a><span class="co">#&gt; F-statistic:   160 on 4 and 193 DF, p-value: &lt; 2.22e-16</span></span></code></pre></div>
<p><span class="math display">\[
\operatorname{Consumption} = 0.25 + 0.74(\operatorname{Income}) + 0.05(\operatorname{Production}) - 0.05(\operatorname{Savings}) - 0.17(\operatorname{Unemployment}) + \epsilon
\]</span></p>
</div>
<div id="assumptions" class="section level3">
<h3><span class="header-section-number">7.1.3</span> Assumptions</h3>
<p>When we use a linear regression model, we are implicitly making some assumptions about the variables in Equation <a href="time-series-regression-models.html#eq:multiple-linear-reg">(7.1)</a>:</p>
<ul>
<li><p>The forecast variable <span class="math inline">\(y_t\)</span> and predictors <span class="math inline">\({x_1, \dots, x_k}\)</span> have a (approximate) <strong>linear</strong> relationship in reality</p></li>
<li><p>Residuals <span class="math inline">\(\varepsilon_t\)</span> are <strong>independent</strong> (not autocorrelated in a time series linear model specifically) and have constant variance <span class="math inline">\(\sigma^2\)</span> and mean <span class="math inline">\(0\)</span> . Otherwise the forecasts will be inefficient, as there is more information in the data that can be exploited. This can be expressed as</p></li>
</ul>
<p><span class="math display" id="eq:GM">\[\begin{equation}  
\tag{7.2}
\begin{aligned}
\text{Cov}(\varepsilon_i, \varepsilon_j) &amp;= 
\begin{cases}
0 &amp; i \not=j \\
\sigma^2 &amp; i = j
\end{cases} 
\;\;\;i,j = 1, 2,\dots,T \\ 
E(\varepsilon_t) &amp;= 0  
\;\;\;t = 1,2,\dots,T
\end{aligned}
\end{equation}\]</span></p>
<p>Equation <a href="time-series-regression-models.html#eq:GM">(7.2)</a> is also called a G-M (Gauss-Markov) condition.</p>
<ul>
<li>Residuals follow a approximate <strong>normal</strong> distribution, meaning:</li>
</ul>
<p><span class="math display">\[
\varepsilon_t \sim N(0, \sigma^2) \;\;\; t = 1,2, \dots,T
\]</span></p>
<p>Another important assumption in the linear regression model is that <strong>each predictor <span class="math inline">\(x\)</span> is not a random variable</strong>. If we were performing a controlled experiment in a laboratory, we could control the values of each <span class="math inline">\(x\)</span> (so they would not be random) and observe the resulting values of <span class="math inline">\(y\)</span>. With observational data (including most data in business and economics), it is not possible to control the value of x, we simply observe it. Hence we make this an assumption.</p>
</div>
</div>
<div id="least-squares-estimation" class="section level2">
<h2><span class="header-section-number">7.2</span> Least squares estimation</h2>
<p>The least squares principle provides a way of choosing the coefficients effectively by minimising the sum of the squared errors. That is, we choose the values of <span class="math inline">\(\beta_0\)</span>,<span class="math inline">\(\beta_1\)</span>,…,<span class="math inline">\(\beta_k\)</span> that minimise :</p>
<p><span class="math display">\[
\sum_{t=1}^{T}{\varepsilon_t^2} = \sum_{t=1}^{T}{(y_t -\beta_0 - \beta_1x_{t1} + \beta_2x_{t2} - \cdots- \beta_kx_{tk})^2}
\]</span></p>
<div id="fitted-values" class="section level3">
<h3><span class="header-section-number">7.2.1</span> Fitted values</h3>
<p>To get fitted values, use <code>broom::augment()</code>:</p>
<div class="sourceCode" id="cb119"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb119-1"><a href="time-series-regression-models.html#cb119-1"></a>us_change_mfit <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb119-2"><a href="time-series-regression-models.html#cb119-2"></a><span class="st">  </span><span class="kw">augment</span>() <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb119-3"><a href="time-series-regression-models.html#cb119-3"></a><span class="st">  </span><span class="kw">pivot_longer</span>(<span class="kw">c</span>(Consumption, .fitted)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb119-4"><a href="time-series-regression-models.html#cb119-4"></a><span class="st">  </span><span class="kw">ggplot</span>() <span class="op">+</span><span class="st"> </span></span>
<span id="cb119-5"><a href="time-series-regression-models.html#cb119-5"></a><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(Quarter, value, <span class="dt">color =</span> name)) <span class="op">+</span></span>
<span id="cb119-6"><a href="time-series-regression-models.html#cb119-6"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">color =</span> <span class="st">&quot;&quot;</span>,</span>
<span id="cb119-7"><a href="time-series-regression-models.html#cb119-7"></a>       <span class="dt">title =</span> <span class="st">&quot;Percent change in US consumption expenditure&quot;</span>)</span></code></pre></div>
<p><img src="ch7_files/figure-html/unnamed-chunk-13-1.png" width="100%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb120"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb120-1"><a href="time-series-regression-models.html#cb120-1"></a>us_change_mfit <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb120-2"><a href="time-series-regression-models.html#cb120-2"></a><span class="st">  </span><span class="kw">augment</span>() <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb120-3"><a href="time-series-regression-models.html#cb120-3"></a><span class="st">  </span><span class="kw">ggplot</span>() <span class="op">+</span><span class="st"> </span></span>
<span id="cb120-4"><a href="time-series-regression-models.html#cb120-4"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(Consumption, .fitted)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb120-5"><a href="time-series-regression-models.html#cb120-5"></a><span class="st">  </span><span class="kw">geom_abline</span>(<span class="dt">intercept =</span> <span class="dv">0</span>, <span class="dt">slope =</span> <span class="dv">1</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb120-6"><a href="time-series-regression-models.html#cb120-6"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Percent change in US consumption expenditure&quot;</span>,</span>
<span id="cb120-7"><a href="time-series-regression-models.html#cb120-7"></a>       <span class="dt">y =</span> <span class="st">&quot;Fitted (predicted values)&quot;</span>,</span>
<span id="cb120-8"><a href="time-series-regression-models.html#cb120-8"></a>       <span class="dt">x =</span> <span class="st">&quot;Data (actual values)&quot;</span>)</span></code></pre></div>
<p><img src="ch7_files/figure-html/unnamed-chunk-14-1.png" width="100%" style="display: block; margin: auto;" /></p>
</div>
<div id="goodness-of-fit" class="section level3">
<h3><span class="header-section-number">7.2.2</span> Goodness of fit</h3>
<p><span class="math display">\[
R^2 = \frac{\sum{(\hat{y}_t - \bar{y})^2}}{\sum{(y_t - \bar{y})^2}}
\]</span></p>
</div>
<div id="standard-error-of-the-regression" class="section level3">
<h3><span class="header-section-number">7.2.3</span> Standard error of the regression</h3>
<p>Estimate residual standard deviation <span class="math inline">\(\hat{\sigma}\)</span>, which is often known as the “residual standard error”:</p>
<p><span class="math display" id="eq:standard-error">\[\begin{equation}
\tag{7.3}
\hat{\sigma} = \sqrt{\frac{1}{T-K-1} \sum_{t=1}^T{e_t^2}}
\end{equation}\]</span></p>
<p>where <span class="math inline">\(k\)</span> is the number of predictors in the model. Notice that we divide by <span class="math inline">\(T− k − 1\)</span> because we have estimated <span class="math inline">\(k + 1\)</span> parameters (the intercept and a coefficient for each predictor variable) in computing the residuals.</p>
<p>The standard error is related to the size of the average error that the model produces. We can compare this error to the sample mean of <span class="math inline">\(y\)</span> or with the standard deviation of <span class="math inline">\(y\)</span> to gain some perspective on the accuracy of the model.</p>
</div>
</div>
<div id="evaluating-a-regression-model" class="section level2">
<h2><span class="header-section-number">7.3</span> Evaluating a regression model</h2>
<p><code>gg_tsresiduals()</code> and Ljung-Box test(<span class="math inline">\(H_0\)</span> being the residuals are from a white noise series) introduced in Section <a href="the-forecasters-toolbox.html#residual-diagnostics">5.4</a></p>
<div class="sourceCode" id="cb121"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb121-1"><a href="time-series-regression-models.html#cb121-1"></a>us_change_mfit <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">gg_tsresiduals</span>()</span></code></pre></div>
<p><img src="ch7_files/figure-html/unnamed-chunk-15-1.png" width="100%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb122"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb122-1"><a href="time-series-regression-models.html#cb122-1"></a>us_change_mfit <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb122-2"><a href="time-series-regression-models.html#cb122-2"></a><span class="st">  </span><span class="kw">augment</span>() <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb122-3"><a href="time-series-regression-models.html#cb122-3"></a><span class="st">  </span><span class="kw">features</span>(.resid, ljung_box, <span class="dt">lag =</span> <span class="dv">10</span>, <span class="dt">dof =</span> <span class="dv">5</span>)</span>
<span id="cb122-4"><a href="time-series-regression-models.html#cb122-4"></a><span class="co">#&gt; # A tibble: 1 x 3</span></span>
<span id="cb122-5"><a href="time-series-regression-models.html#cb122-5"></a><span class="co">#&gt;   .model                                                       lb_stat lb_pvalue</span></span>
<span id="cb122-6"><a href="time-series-regression-models.html#cb122-6"></a><span class="co">#&gt;   &lt;chr&gt;                                                          &lt;dbl&gt;     &lt;dbl&gt;</span></span>
<span id="cb122-7"><a href="time-series-regression-models.html#cb122-7"></a><span class="co">#&gt; 1 TSLM(Consumption ~ Income + Production + Savings + Unemploy~    18.9   0.00204</span></span></code></pre></div>
<p>The time plot shows some changing variation over time, but is otherwise relatively unremarkable. This heteroscedasticity will potentially make the prediction interval coverage inaccurate.</p>
<p>The histogram shows that the residuals seem to be slightly skewed, which may also affect the coverage probability of the prediction intervals.</p>
<p>The autocorrelation plot shows a significant spike at lag <span class="math inline">\(7\)</span>, and a significant Ljung-Box test at the <span class="math inline">\(5\%\)</span> level. However, the autocorrelation is not particularly large, and at lag 7 it is unlikely to have any noticeable impact on the forecasts or the prediction intervals. In Chapter <a href="dynamic-regression-models.html#dynamic-regression-models">11</a> we discuss dynamic regression models used for better capturing information left in the residuals.</p>
<div id="residual-plots-against-predictors" class="section level3">
<h3><span class="header-section-number">7.3.1</span> Residual plots against predictors</h3>
<p>We would expect the residuals to be randomly scattered without showing any systematic patterns. A simple and quick way to check this is to examine scatterplots of the residuals against each of the predictor variables. If these scatterplots show a pattern, then the relationship may be nonlinear and the model will need to be modified accordingly. See Section <a href="time-series-regression-models.html#nonlinear-regression">7.8</a> for a discussion of nonlinear regression.</p>
<p>It is also necessary to plot the residuals against any predictors that are <em>not</em> in the model. If any of these show a pattern, then the corresponding predictor may need to be added to the model (possibly in a nonlinear form).</p>
<div id="example" class="section level4">
<h4><span class="header-section-number">7.3.1.1</span> Example</h4>
<p><code>residuals()</code>allow us to extract residuals from a <code>fable</code> object, without calling <code>augment()</code>.</p>
<p>The residuals from the multiple regression model for forecasting US consumption plotted against each predictor seem to be randomly scattered. Therefore we are satisfied with these in this case.</p>
<div class="sourceCode" id="cb123"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb123-1"><a href="time-series-regression-models.html#cb123-1"></a>df &lt;-<span class="st"> </span>us_change <span class="op">%&gt;%</span></span>
<span id="cb123-2"><a href="time-series-regression-models.html#cb123-2"></a><span class="st">  </span><span class="kw">left_join</span>(us_change_mfit <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">residuals</span>(), <span class="dt">by =</span> <span class="st">&quot;Quarter&quot;</span>)</span>
<span id="cb123-3"><a href="time-series-regression-models.html#cb123-3"></a></span>
<span id="cb123-4"><a href="time-series-regression-models.html#cb123-4"></a><span class="kw">library</span>(patchwork)</span>
<span id="cb123-5"><a href="time-series-regression-models.html#cb123-5"></a>p1 &lt;-<span class="st"> </span><span class="kw">ggplot</span>(df, <span class="kw">aes</span>(Income, .resid)) <span class="op">+</span></span>
<span id="cb123-6"><a href="time-series-regression-models.html#cb123-6"></a><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span><span class="st"> </span><span class="kw">ylab</span>(<span class="st">&quot;Residuals&quot;</span>)</span>
<span id="cb123-7"><a href="time-series-regression-models.html#cb123-7"></a>p2 &lt;-<span class="st"> </span><span class="kw">ggplot</span>(df, <span class="kw">aes</span>(Production, .resid)) <span class="op">+</span></span>
<span id="cb123-8"><a href="time-series-regression-models.html#cb123-8"></a><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span><span class="st"> </span><span class="kw">ylab</span>(<span class="st">&quot;Residuals&quot;</span>)</span>
<span id="cb123-9"><a href="time-series-regression-models.html#cb123-9"></a>p3 &lt;-<span class="st"> </span><span class="kw">ggplot</span>(df, <span class="kw">aes</span>(Savings, .resid)) <span class="op">+</span></span>
<span id="cb123-10"><a href="time-series-regression-models.html#cb123-10"></a><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span><span class="st"> </span><span class="kw">ylab</span>(<span class="st">&quot;Residuals&quot;</span>)</span>
<span id="cb123-11"><a href="time-series-regression-models.html#cb123-11"></a>p4 &lt;-<span class="st"> </span><span class="kw">ggplot</span>(df, <span class="kw">aes</span>(Unemployment, .resid)) <span class="op">+</span></span>
<span id="cb123-12"><a href="time-series-regression-models.html#cb123-12"></a><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span><span class="st"> </span><span class="kw">ylab</span>(<span class="st">&quot;Residuals&quot;</span>)</span>
<span id="cb123-13"><a href="time-series-regression-models.html#cb123-13"></a></span>
<span id="cb123-14"><a href="time-series-regression-models.html#cb123-14"></a>p1 <span class="op">+</span><span class="st"> </span>p2 <span class="op">+</span><span class="st"> </span>p3 <span class="op">+</span><span class="st"> </span>p4 <span class="op">+</span><span class="st"> </span><span class="kw">plot_layout</span>(<span class="dt">nrow =</span> <span class="dv">2</span>)</span></code></pre></div>
<p><img src="ch7_files/figure-html/unnamed-chunk-17-1.png" width="100%" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="residual-plots-against-fitted-values" class="section level3">
<h3><span class="header-section-number">7.3.2</span> Residual plots against fitted values</h3>
<p>A plot of the residuals against the fitted values should also show no pattern. If a pattern is observed, there may be “heteroscedasticity”, or <strong>non-constant variance</strong>. If this problem occurs, a transformation of the forecast variable such as a logarithm or square root may be required (see Section <a href="time-series-decomposition.html#transformation-and-adjustments">3.1</a>.)</p>
<div id="example-1" class="section level4">
<h4><span class="header-section-number">7.3.2.1</span> Example</h4>
<p>The following plot shows the residuals plotted against the fitted values. The random scatter suggests the errors are homoscedastic.</p>
<div class="sourceCode" id="cb124"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb124-1"><a href="time-series-regression-models.html#cb124-1"></a><span class="kw">augment</span>(us_change_mfit) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb124-2"><a href="time-series-regression-models.html#cb124-2"></a><span class="st">  </span><span class="kw">ggplot</span>()<span class="op">+</span><span class="st"> </span></span>
<span id="cb124-3"><a href="time-series-regression-models.html#cb124-3"></a><span class="st">  </span><span class="kw">geom_point</span>(<span class="kw">aes</span>(.fitted, .resid)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb124-4"><a href="time-series-regression-models.html#cb124-4"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Fitted&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Residuals&quot;</span>)</span></code></pre></div>
<p><img src="ch7_files/figure-html/unnamed-chunk-18-1.png" width="100%" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="outliers-and-influential-observations" class="section level3">
<h3><span class="header-section-number">7.3.3</span> Outliers and influential observations</h3>
<p>Observations that take extreme values compared to the majority of the data are called outliers. Observations that have a large influence on the estimated coefficients of a regression model are called influential observations. Usually, influential observations are also outliers that are extreme in the <span class="math inline">\(x\)</span> direction.</p>
<p><strong>It is useful to distinguish outliers from anomalies</strong>. An outlier is mathematically stated as any observation point in given data-set that is more than 1.5 interquartile ranges (IQRs) below the first quartile or above the third quartile. Anomaly is items, events or observations which do not conform to an expected pattern (staistical distributions), simply anything “outside normal”. It can be noise, deviations and exceptions defined in application of particular system. The <a href="https://github.com/business-science/anomalize">anomalize</a> package provides tools in anomaly detection and visualization.</p>
<p>For a formal detection of observation influence, the <strong>leverage</strong> of the t-th observation <span class="math inline">\({x_{1t}, x_{2t}, \dots, {x_{kt}}\)</span> is defined as the t-th diagonal element of the hat matrix <span class="math inline">\(H = X(X^TX)^{-1}X^T\)</span>, i.e. <span class="math inline">\(h_{tt}\)</span>.</p>
<p>And the <strong>Cook distance</strong> of the i-th observation is defined as :</p>
<p><span class="math display">\[
C_t = \frac{r_t^2}{k + 2} \times \frac{h_{tt}}{1 - h_{tt}}
\]</span></p>
<p>where <span class="math inline">\(k\)</span> is the number of predictors and <span class="math inline">\(r_t\)</span> the i-th internally studentized residuals <span class="math inline">\(r_t = \frac{e_t}{\hat{\sigma}\sqrt{1-h_{tt}}}\)</span></p>
<p>Finding influential observations in practice is not covered in the book. So I followed instructions from another book: <em>An R Companion to Applied Regression, 3rd</em> <span class="citation">(Fox and Weisberg <a href="references.html#ref-fox2018r" role="doc-biblioref">2018</a>)</span>.</p>
<div class="sourceCode" id="cb125"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb125-1"><a href="time-series-regression-models.html#cb125-1"></a>us_change_lm &lt;-<span class="st"> </span><span class="kw">lm</span>(Consumption <span class="op">~</span><span class="st"> </span>Income <span class="op">+</span><span class="st"> </span>Production <span class="op">+</span><span class="st"> </span>Savings <span class="op">+</span><span class="st"> </span>Unemployment, </span>
<span id="cb125-2"><a href="time-series-regression-models.html#cb125-2"></a>                    <span class="dt">data =</span> us_change)</span></code></pre></div>
<div class="sourceCode" id="cb126"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb126-1"><a href="time-series-regression-models.html#cb126-1"></a>us_change_lm <span class="op">%&gt;%</span><span class="st"> </span>car<span class="op">::</span><span class="kw">influenceIndexPlot</span>()</span></code></pre></div>
<p><img src="ch7_files/figure-html/unnamed-chunk-20-1.png" width="100%" style="display: block; margin: auto;" /></p>
</div>
<div id="the-performance-package" class="section level3">
<h3><span class="header-section-number">7.3.4</span> The <code>performance</code> package</h3>
<p>The <a href="https://easystats.github.io/performance/">performance</a> package is dedicated to providing utilities for computing indices of model quality and goodness of fit. In the case of regression, <code>performance</code> provides many functions to check model assumptions, like <code>check_collinearity()</code>, <code>check_normality()</code> or <code>check_heteroscedasticity()</code>. To get a comprehensive check, use <code>check_model()</code></p>
<div class="sourceCode" id="cb127"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb127-1"><a href="time-series-regression-models.html#cb127-1"></a><span class="kw">library</span>(performance)</span>
<span id="cb127-2"><a href="time-series-regression-models.html#cb127-2"></a><span class="kw">check_model</span>(us_change_lm)</span></code></pre></div>
<p><img src="ch7_files/figure-html/unnamed-chunk-21-1.png" width="100%" style="display: block; margin: auto;" /></p>
</div>
<div id="spurious-regression" class="section level3">
<h3><span class="header-section-number">7.3.5</span> Spurious regression</h3>
<p>Time series data are often “non-stationary”. That is, the values of the time series do not fluctuate around a constant mean or with a constant variance. We will come to the formal definition of stationarity in more detail in Section <a href="univariate-stationary-processes.html#stationarity">9.1</a>, but here we need to address the effect that non-stationary data can have on regression models.</p>
<p>For example, consider the two variables plotted in below. These appear to be related simply because they both trend upwards in the same manner. However, air passenger traffic in Australia has nothing to do with rice production in Guinea.</p>
<div class="sourceCode" id="cb128"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb128-1"><a href="time-series-regression-models.html#cb128-1"></a>guinea_rice &lt;-<span class="st"> </span>fpp3<span class="op">::</span>guinea_rice</span>
<span id="cb128-2"><a href="time-series-regression-models.html#cb128-2"></a>air_passengers &lt;-<span class="st"> </span>fpp3<span class="op">::</span>aus_airpassengers</span>
<span id="cb128-3"><a href="time-series-regression-models.html#cb128-3"></a></span>
<span id="cb128-4"><a href="time-series-regression-models.html#cb128-4"></a>p1 &lt;-<span class="st"> </span>guinea_rice <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">autoplot</span>() <span class="op">+</span><span class="st"> </span><span class="kw">ggtitle</span>(<span class="st">&quot;Guinea rice production&quot;</span>)</span>
<span id="cb128-5"><a href="time-series-regression-models.html#cb128-5"></a>p2 &lt;-<span class="st"> </span>air_passengers <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">autoplot</span>() <span class="op">+</span><span class="st"> </span><span class="kw">ggtitle</span>(<span class="st">&quot;Australia air passengers&quot;</span>)</span>
<span id="cb128-6"><a href="time-series-regression-models.html#cb128-6"></a>p3 &lt;-<span class="st"> </span>guinea_rice <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb128-7"><a href="time-series-regression-models.html#cb128-7"></a><span class="st">    </span><span class="kw">left_join</span>(air_passengers) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb128-8"><a href="time-series-regression-models.html#cb128-8"></a><span class="st">    </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(Production, Passengers)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb128-9"><a href="time-series-regression-models.html#cb128-9"></a><span class="st">    </span><span class="kw">geom_point</span>() <span class="op">+</span></span>
<span id="cb128-10"><a href="time-series-regression-models.html#cb128-10"></a><span class="st">    </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">se =</span> <span class="ot">FALSE</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb128-11"><a href="time-series-regression-models.html#cb128-11"></a><span class="st">    </span><span class="kw">ggtitle</span>(<span class="st">&quot;A well-fitted regression line&quot;</span>)</span>
<span id="cb128-12"><a href="time-series-regression-models.html#cb128-12"></a></span>
<span id="cb128-13"><a href="time-series-regression-models.html#cb128-13"></a>(p1 <span class="op">/</span><span class="st"> </span>p2) <span class="op">|</span><span class="st"> </span>p3 </span></code></pre></div>
<p><img src="ch7_files/figure-html/unnamed-chunk-22-1.png" width="100%" style="display: block; margin: auto;" /></p>
<p>Regressing non-stationary time series can lead to spurious regressions. <strong>High <span class="math inline">\(R^2\)</span> and high residual autocorrelation can be signs of spurious regression</strong>. Notice these features in the output below. We discuss the issues surrounding non-stationary data and spurious regressions in more details in Chapter <a href="dynamic-regression-models.html#dynamic-regression-models">11</a>.</p>
<p>Cases of spurious regression might appear to give reasonable short-term forecasts, but they will generally not continue to work into the future.</p>
<div class="sourceCode" id="cb129"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb129-1"><a href="time-series-regression-models.html#cb129-1"></a>spurious_fit &lt;-<span class="st"> </span>guinea_rice <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb129-2"><a href="time-series-regression-models.html#cb129-2"></a><span class="st">  </span><span class="kw">left_join</span>(air_passengers) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb129-3"><a href="time-series-regression-models.html#cb129-3"></a><span class="st">  </span><span class="kw">lm</span>(Passengers <span class="op">~</span><span class="st"> </span>Production, <span class="dt">data =</span> .) </span>
<span id="cb129-4"><a href="time-series-regression-models.html#cb129-4"></a></span>
<span id="cb129-5"><a href="time-series-regression-models.html#cb129-5"></a><span class="co"># high r^2 and sigma</span></span>
<span id="cb129-6"><a href="time-series-regression-models.html#cb129-6"></a><span class="kw">glance</span>(spurious_fit)</span>
<span id="cb129-7"><a href="time-series-regression-models.html#cb129-7"></a><span class="co">#&gt; # A tibble: 1 x 12</span></span>
<span id="cb129-8"><a href="time-series-regression-models.html#cb129-8"></a><span class="co">#&gt;   r.squared adj.r.squared sigma statistic  p.value    df logLik   AIC   BIC</span></span>
<span id="cb129-9"><a href="time-series-regression-models.html#cb129-9"></a><span class="co">#&gt;       &lt;dbl&gt;         &lt;dbl&gt; &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;dbl&gt;  &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;</span></span>
<span id="cb129-10"><a href="time-series-regression-models.html#cb129-10"></a><span class="co">#&gt; 1     0.958         0.957  3.24      908. 4.08e-29     1  -108.  222.  227.</span></span>
<span id="cb129-11"><a href="time-series-regression-models.html#cb129-11"></a><span class="co">#&gt; # ... with 3 more variables: deviance &lt;dbl&gt;, df.residual &lt;int&gt;, nobs &lt;int&gt;</span></span></code></pre></div>
<p>Section <a href="univariate-stationary-processes.html#tests-for-autocorrelation-and-normality">9.1.2</a> introduces the BG test, which is designed to detect autocorrelation among residuals of a regression model, small p-value suggests that residuals are highly correlated</p>
<div class="sourceCode" id="cb130"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb130-1"><a href="time-series-regression-models.html#cb130-1"></a>spurious_fit <span class="op">%&gt;%</span><span class="st"> </span>lmtest<span class="op">::</span><span class="kw">bgtest</span>()</span>
<span id="cb130-2"><a href="time-series-regression-models.html#cb130-2"></a><span class="co">#&gt; </span></span>
<span id="cb130-3"><a href="time-series-regression-models.html#cb130-3"></a><span class="co">#&gt; 	Breusch-Godfrey test for serial correlation of order up to 1</span></span>
<span id="cb130-4"><a href="time-series-regression-models.html#cb130-4"></a><span class="co">#&gt; </span></span>
<span id="cb130-5"><a href="time-series-regression-models.html#cb130-5"></a><span class="co">#&gt; data:  .</span></span>
<span id="cb130-6"><a href="time-series-regression-models.html#cb130-6"></a><span class="co">#&gt; LM test = 23.309, df = 1, p-value = 0.00000138</span></span></code></pre></div>
</div>
</div>
<div id="some-useful-predictors" class="section level2">
<h2><span class="header-section-number">7.4</span> Some useful predictors</h2>
<p>There are several useful predictors that occur frequently when using regression for time series data.</p>
<div id="trend" class="section level3">
<h3><span class="header-section-number">7.4.1</span> Trend</h3>
<p>It is common for time series data to be trending. A linear trend can be modelled by simply using <span class="math inline">\(x_{1t} = t\)</span> as a predictor</p>
<p><span class="math display">\[
y_t = \beta_0 + \beta_1 t + \varepsilon
\]</span></p>
<p>where <span class="math inline">\(t = 1, 2, \dots, T\)</span></p>
<p>A trend variable can be specified in the <code>TSLM()</code> function using the <code>trend()</code> special. In Section <a href="time-series-regression-models.html#nonlinear-regression">7.8</a> we discuss how we can also model a nonlinear trends.</p>
</div>
<div id="seasonal-dummy-variables" class="section level3">
<h3><span class="header-section-number">7.4.2</span> Seasonal dummy variables</h3>
<p>If the time sereis data shows storng seasonality in some fashion, we tend to add seasonaly dummy variables to include this seasonality in our model.
The <code>TSLM()</code> function will automatically handle this situation if you specify the special <code>season()</code>. For example, if we are modelling daily data (<span class="math inline">\(period = 7\)</span>), 6 dummy variables will be created.</p>
</div>
<div id="example-australian-quarterly-beer-production" class="section level3">
<h3><span class="header-section-number">7.4.3</span> Example: Australian quarterly beer production</h3>
<p>Recall the Australian quarterly beer production data</p>
<div class="sourceCode" id="cb131"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb131-1"><a href="time-series-regression-models.html#cb131-1"></a>recent_production &lt;-<span class="st"> </span>aus_production <span class="op">%&gt;%</span></span>
<span id="cb131-2"><a href="time-series-regression-models.html#cb131-2"></a><span class="st">  </span><span class="kw">filter</span>(<span class="kw">year</span>(Quarter) <span class="op">&gt;=</span><span class="st"> </span><span class="dv">1992</span>)  </span>
<span id="cb131-3"><a href="time-series-regression-models.html#cb131-3"></a></span>
<span id="cb131-4"><a href="time-series-regression-models.html#cb131-4"></a></span>
<span id="cb131-5"><a href="time-series-regression-models.html#cb131-5"></a>recent_production <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">gg_tsdisplay</span>(Beer)</span></code></pre></div>
<p><img src="ch7_files/figure-html/unnamed-chunk-25-1.png" width="100%" style="display: block; margin: auto;" /></p>
<p>We want to forecast the value of future beer production. We can model this data using a regression model with a linear trend and quarterly dummy variables,</p>
<p><span class="math display">\[
y_t = \beta_0 + \beta_1 x_{1t} + \beta_2 d_{2t} + \beta_3 d_{3t}+ \beta_4 d_{4t}
\]</span>
where <span class="math inline">\(d_{2t}\)</span>, <span class="math inline">\(d_{3t}\)</span> and <span class="math inline">\(d_{4t}\)</span> are dummy variables representing 3 of all 4 seasons except the first.</p>
<div class="sourceCode" id="cb132"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb132-1"><a href="time-series-regression-models.html#cb132-1"></a>beer_fit &lt;-<span class="st"> </span>recent_production <span class="op">%&gt;%</span></span>
<span id="cb132-2"><a href="time-series-regression-models.html#cb132-2"></a><span class="st">  </span><span class="kw">model</span>(<span class="kw">TSLM</span>(Beer <span class="op">~</span><span class="st"> </span><span class="kw">trend</span>() <span class="op">+</span><span class="st"> </span><span class="kw">season</span>()))</span>
<span id="cb132-3"><a href="time-series-regression-models.html#cb132-3"></a></span>
<span id="cb132-4"><a href="time-series-regression-models.html#cb132-4"></a>beer_fit <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">report</span>()</span>
<span id="cb132-5"><a href="time-series-regression-models.html#cb132-5"></a><span class="co">#&gt; Series: Beer </span></span>
<span id="cb132-6"><a href="time-series-regression-models.html#cb132-6"></a><span class="co">#&gt; Model: TSLM </span></span>
<span id="cb132-7"><a href="time-series-regression-models.html#cb132-7"></a><span class="co">#&gt; </span></span>
<span id="cb132-8"><a href="time-series-regression-models.html#cb132-8"></a><span class="co">#&gt; Residuals:</span></span>
<span id="cb132-9"><a href="time-series-regression-models.html#cb132-9"></a><span class="co">#&gt;      Min       1Q   Median       3Q      Max </span></span>
<span id="cb132-10"><a href="time-series-regression-models.html#cb132-10"></a><span class="co">#&gt; -42.9029  -7.5995  -0.4594   7.9908  21.7895 </span></span>
<span id="cb132-11"><a href="time-series-regression-models.html#cb132-11"></a><span class="co">#&gt; </span></span>
<span id="cb132-12"><a href="time-series-regression-models.html#cb132-12"></a><span class="co">#&gt; Coefficients:</span></span>
<span id="cb132-13"><a href="time-series-regression-models.html#cb132-13"></a><span class="co">#&gt;                Estimate Std. Error t value             Pr(&gt;|t|)    </span></span>
<span id="cb132-14"><a href="time-series-regression-models.html#cb132-14"></a><span class="co">#&gt; (Intercept)   441.80044    3.73353 118.333 &lt; 0.0000000000000002 ***</span></span>
<span id="cb132-15"><a href="time-series-regression-models.html#cb132-15"></a><span class="co">#&gt; trend()        -0.34027    0.06657  -5.111     0.00000272965382 ***</span></span>
<span id="cb132-16"><a href="time-series-regression-models.html#cb132-16"></a><span class="co">#&gt; season()year2 -34.65973    3.96832  -8.734     0.00000000000091 ***</span></span>
<span id="cb132-17"><a href="time-series-regression-models.html#cb132-17"></a><span class="co">#&gt; season()year3 -17.82164    4.02249  -4.430     0.00003449674545 ***</span></span>
<span id="cb132-18"><a href="time-series-regression-models.html#cb132-18"></a><span class="co">#&gt; season()year4  72.79641    4.02305  18.095 &lt; 0.0000000000000002 ***</span></span>
<span id="cb132-19"><a href="time-series-regression-models.html#cb132-19"></a><span class="co">#&gt; ---</span></span>
<span id="cb132-20"><a href="time-series-regression-models.html#cb132-20"></a><span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></span>
<span id="cb132-21"><a href="time-series-regression-models.html#cb132-21"></a><span class="co">#&gt; </span></span>
<span id="cb132-22"><a href="time-series-regression-models.html#cb132-22"></a><span class="co">#&gt; Residual standard error: 12.23 on 69 degrees of freedom</span></span>
<span id="cb132-23"><a href="time-series-regression-models.html#cb132-23"></a><span class="co">#&gt; Multiple R-squared: 0.9243,	Adjusted R-squared: 0.9199</span></span>
<span id="cb132-24"><a href="time-series-regression-models.html#cb132-24"></a><span class="co">#&gt; F-statistic: 210.7 on 4 and 69 DF, p-value: &lt; 0.000000000000000222</span></span></code></pre></div>
<p>Note that <code>trend()</code> and <code>season()</code> are not standard functions; they are “special” functions that work within the <code>TSLM()</code> model formulae.</p>
<p>There is an average downward trend of -0.34 megalitres per quarter. On average, the second quarter has production of 34.7 megalitres lower than the first quarter, the third quarter has production of 17.8 megalitres lower than the first quarter, and the fourth quarter has production of 72.8 megalitres higher than the first quarter.</p>
<div class="sourceCode" id="cb133"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb133-1"><a href="time-series-regression-models.html#cb133-1"></a><span class="kw">augment</span>(beer_fit) <span class="op">%&gt;%</span></span>
<span id="cb133-2"><a href="time-series-regression-models.html#cb133-2"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> Quarter)) <span class="op">+</span></span>
<span id="cb133-3"><a href="time-series-regression-models.html#cb133-3"></a><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">y =</span> Beer, <span class="dt">colour =</span> <span class="st">&quot;Data&quot;</span>)) <span class="op">+</span></span>
<span id="cb133-4"><a href="time-series-regression-models.html#cb133-4"></a><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">y =</span> .fitted, <span class="dt">colour =</span> <span class="st">&quot;Fitted&quot;</span>)) <span class="op">+</span></span>
<span id="cb133-5"><a href="time-series-regression-models.html#cb133-5"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Year&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;Megalitres&quot;</span>,</span>
<span id="cb133-6"><a href="time-series-regression-models.html#cb133-6"></a>       <span class="dt">title =</span> <span class="st">&quot;Quarterly Beer Production&quot;</span>)</span></code></pre></div>
<p><img src="ch7_files/figure-html/unnamed-chunk-27-1.png" width="100%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb134"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb134-1"><a href="time-series-regression-models.html#cb134-1"></a><span class="kw">augment</span>(beer_fit) <span class="op">%&gt;%</span></span>
<span id="cb134-2"><a href="time-series-regression-models.html#cb134-2"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(<span class="dt">x =</span> Beer, <span class="dt">y =</span> .fitted,</span>
<span id="cb134-3"><a href="time-series-regression-models.html#cb134-3"></a>             <span class="dt">colour =</span> <span class="kw">factor</span>(<span class="kw">quarter</span>(Quarter)))) <span class="op">+</span></span>
<span id="cb134-4"><a href="time-series-regression-models.html#cb134-4"></a><span class="st">    </span><span class="kw">geom_point</span>() <span class="op">+</span></span>
<span id="cb134-5"><a href="time-series-regression-models.html#cb134-5"></a><span class="st">    </span><span class="kw">scale_colour_brewer</span>(<span class="dt">palette=</span><span class="st">&quot;Dark2&quot;</span>, <span class="dt">name=</span><span class="st">&quot;Quarter&quot;</span>) <span class="op">+</span></span>
<span id="cb134-6"><a href="time-series-regression-models.html#cb134-6"></a><span class="st">    </span><span class="kw">geom_abline</span>(<span class="dt">intercept =</span> <span class="dv">0</span>, <span class="dt">slope =</span> <span class="dv">1</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb134-7"><a href="time-series-regression-models.html#cb134-7"></a><span class="st">    </span><span class="kw">labs</span>(<span class="dt">y =</span> <span class="st">&quot;Fitted&quot;</span>, <span class="dt">x =</span> <span class="st">&quot;Actual values&quot;</span>,</span>
<span id="cb134-8"><a href="time-series-regression-models.html#cb134-8"></a>         <span class="dt">title =</span> <span class="st">&quot;Quarterly beer production&quot;</span>)</span></code></pre></div>
<p><img src="ch7_files/figure-html/unnamed-chunk-28-1.png" width="100%" style="display: block; margin: auto;" /></p>
</div>
<div id="intervention-variables" class="section level3">
<h3><span class="header-section-number">7.4.4</span> Intervention variables</h3>
<p>It is often necessary to model interventions that may have affected the variable to be forecast. For example, competitor activity, advertising expenditure, industrial action, and so on, can all have an effect.</p>
<p>When the effect lasts only for one period, we use a <strong>spike variable</strong>. This is a dummy variable that takes value one in the period of the intervention and zero elsewhere. A spike variable is equivalent to a dummy variable for handling an outlier.</p>
<p>Other interventions have an immediate and permanent effect. If an intervention causes a level shift (i.e., the value of the series changes suddenly and permanently from the time of intervention), then we use a <strong>step variable</strong>. A step variable takes value zero before the intervention and one from the time of intervention onward.</p>
<p>Another form of permanent effect is a change of slope. Here the intervention is handled using a piecewise linear trend; a trend that bends at the time of intervention and hence is nonlinear. We will discuss this in Section <a href="time-series-regression-models.html#nonlinear-regression">7.8</a>.</p>
</div>
<div id="trading-days" class="section level3">
<h3><span class="header-section-number">7.4.5</span> Trading days</h3>
<p>The number of trading days in a month can vary considerably and can have a substantial effect on sales data. To allow for this, the number of trading days in each month can be included as a predictor.</p>
<p>An alternative that allows for the effects of different days of the week has the following predictors:</p>
<p><span class="math display">\[
\begin{aligned}
x_1 &amp;= \text{number of Mondays in the month} \\
x_2 &amp;= \text{number of Tuesdays in the month} \\
... \\
x_7 &amp;= \text{number of Sundays in the month} \\
\end{aligned}
\]</span></p>
</div>
<div id="distributed-lags" class="section level3">
<h3><span class="header-section-number">7.4.6</span> Distributed lags</h3>
<p>It is often useful to include advertising expenditure as a predictor. However, since the effect of advertising can last beyond the actual campaign, we need to include lagged values of advertising expenditure. Thus, the following predictors may be used.</p>
<p><span class="math display">\[
\begin{aligned}
x_1 &amp;= \text{expenditure in the last month} \\
x_2 &amp;= \text{expenditure in the last 2 month} \\
... \\
x_m &amp;= \text{expenditure in the last m month} \\
\end{aligned}
\]</span>
It is common to require the coefficients to decrease as the lag increases, although this is beyond the scope of the book.</p>
</div>
<div id="easter" class="section level3">
<h3><span class="header-section-number">7.4.7</span> Easter</h3>
<p>Easter differs from most holidays because it is not held on the same date each year, and its effect can last for several days. In this case, a dummy variable can be used with value one where the holiday falls in the particular time period and zero otherwise.</p>
<p>With monthly data, if Easter falls in March then the dummy variable takes value 1 in March, and if it falls in April the dummy variable takes value 1 in April. When Easter starts in March and finishes in April, the dummy variable is split proportionally between months.</p>
</div>
<div id="fourier-sereis" class="section level3">
<h3><span class="header-section-number">7.4.8</span> Fourier sereis</h3>
<p>An alternative to using seasonal dummy variables, especially for long seasonal periods, is to use Fourier terms, which, proved by French mathematician Jean-Baptiste Fourier in the 1800s, can approximate any periodic function. We can use them for seasonal patterns.</p>
<p>If <span class="math inline">\(m\)</span> is the seasonal period, then the first few Fourier terms (6 listed here) are given by:<br />
<span class="math display">\[
\begin{aligned}
x_{1t} &amp;= \cos{\frac{2 \pi t}{m}} \\
x_{2t} &amp;= \sin{\frac{2 \pi t}{m}} \\
x_{3t} &amp;= \cos{\frac{4 \pi t}{m}} \\
x_{4t} &amp;= \sin{\frac{4 \pi t}{m}} \\
x_{5t} &amp;= \cos{\frac{6 \pi t}{m}} \\
x_{6t} &amp;= \sin{\frac{6 \pi t}{m}} \\
\end{aligned}
\]</span></p>
<p>and so on. If we have monthly seasonality, and we use the first 11 of these predictor variables, then we will get exactly the same forecasts as using 11 dummy variables.</p>
<p>With Fourier terms, we often need fewer predictors than with dummy variables, especially when m is large. This makes them useful for weekly data, for example, where <span class="math inline">\(m \approx 52\)</span>. For short seasonal periods (e.g., quarterly data), there is little advantage in using Fourier terms over seasonal dummy variables.</p>
<p>These Fourier terms are produced using the <code>fourier(K)</code> function. The <code>K</code> argument specifies the maximum order of Fourier terms (i.e., how many pairs of <span class="math inline">\(\sin\)</span> and <span class="math inline">\(\cos\)</span> terms to include). For example, the Australian beer data (quarterly, should include 3 terms so <code>K = 2</code>) can be modelled like this.</p>
<div class="sourceCode" id="cb135"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb135-1"><a href="time-series-regression-models.html#cb135-1"></a>fourier_beer &lt;-<span class="st"> </span>recent_production <span class="op">%&gt;%</span></span>
<span id="cb135-2"><a href="time-series-regression-models.html#cb135-2"></a><span class="st">  </span><span class="kw">model</span>(<span class="kw">TSLM</span>(Beer <span class="op">~</span><span class="st"> </span><span class="kw">trend</span>() <span class="op">+</span><span class="st"> </span><span class="kw">fourier</span>(<span class="dt">K =</span> <span class="dv">2</span>)))</span>
<span id="cb135-3"><a href="time-series-regression-models.html#cb135-3"></a></span>
<span id="cb135-4"><a href="time-series-regression-models.html#cb135-4"></a>fourier_beer <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">report</span>()</span>
<span id="cb135-5"><a href="time-series-regression-models.html#cb135-5"></a><span class="co">#&gt; Series: Beer </span></span>
<span id="cb135-6"><a href="time-series-regression-models.html#cb135-6"></a><span class="co">#&gt; Model: TSLM </span></span>
<span id="cb135-7"><a href="time-series-regression-models.html#cb135-7"></a><span class="co">#&gt; </span></span>
<span id="cb135-8"><a href="time-series-regression-models.html#cb135-8"></a><span class="co">#&gt; Residuals:</span></span>
<span id="cb135-9"><a href="time-series-regression-models.html#cb135-9"></a><span class="co">#&gt;      Min       1Q   Median       3Q      Max </span></span>
<span id="cb135-10"><a href="time-series-regression-models.html#cb135-10"></a><span class="co">#&gt; -42.9029  -7.5995  -0.4594   7.9908  21.7895 </span></span>
<span id="cb135-11"><a href="time-series-regression-models.html#cb135-11"></a><span class="co">#&gt; </span></span>
<span id="cb135-12"><a href="time-series-regression-models.html#cb135-12"></a><span class="co">#&gt; Coefficients:</span></span>
<span id="cb135-13"><a href="time-series-regression-models.html#cb135-13"></a><span class="co">#&gt;                     Estimate Std. Error t value             Pr(&gt;|t|)    </span></span>
<span id="cb135-14"><a href="time-series-regression-models.html#cb135-14"></a><span class="co">#&gt; (Intercept)        446.87920    2.87321 155.533 &lt; 0.0000000000000002 ***</span></span>
<span id="cb135-15"><a href="time-series-regression-models.html#cb135-15"></a><span class="co">#&gt; trend()             -0.34027    0.06657  -5.111  0.00000272965382379 ***</span></span>
<span id="cb135-16"><a href="time-series-regression-models.html#cb135-16"></a><span class="co">#&gt; fourier(K = 2)C1_4   8.91082    2.01125   4.430  0.00003449674544834 ***</span></span>
<span id="cb135-17"><a href="time-series-regression-models.html#cb135-17"></a><span class="co">#&gt; fourier(K = 2)S1_4 -53.72807    2.01125 -26.714 &lt; 0.0000000000000002 ***</span></span>
<span id="cb135-18"><a href="time-series-regression-models.html#cb135-18"></a><span class="co">#&gt; fourier(K = 2)C2_4 -13.98958    1.42256  -9.834  0.00000000000000926 ***</span></span>
<span id="cb135-19"><a href="time-series-regression-models.html#cb135-19"></a><span class="co">#&gt; ---</span></span>
<span id="cb135-20"><a href="time-series-regression-models.html#cb135-20"></a><span class="co">#&gt; Signif. codes:  0 &#39;***&#39; 0.001 &#39;**&#39; 0.01 &#39;*&#39; 0.05 &#39;.&#39; 0.1 &#39; &#39; 1</span></span>
<span id="cb135-21"><a href="time-series-regression-models.html#cb135-21"></a><span class="co">#&gt; </span></span>
<span id="cb135-22"><a href="time-series-regression-models.html#cb135-22"></a><span class="co">#&gt; Residual standard error: 12.23 on 69 degrees of freedom</span></span>
<span id="cb135-23"><a href="time-series-regression-models.html#cb135-23"></a><span class="co">#&gt; Multiple R-squared: 0.9243,	Adjusted R-squared: 0.9199</span></span>
<span id="cb135-24"><a href="time-series-regression-models.html#cb135-24"></a><span class="co">#&gt; F-statistic: 210.7 on 4 and 69 DF, p-value: &lt; 0.000000000000000222</span></span></code></pre></div>
<p>The maximum allowed is <span class="math inline">\(K = m / 2\)</span> where <span class="math inline">\(m\)</span> is the seasonal period. Because we have used the maximum here, the results are identical to those obtained when using seasonal dummy variables.</p>
<p>If only the first two Fourier terms are used (<span class="math inline">\(x_{1t}\)</span> and <span class="math inline">\(x_{2t}\)</span>), the seasonal pattern will follow a simple sine wave. A regression model containing Fourier terms is often called a <strong>harmonic regression</strong> because the successive Fourier terms represent harmonics of the first two Fourier terms.</p>
</div>
</div>
<div id="selecting-predictors" class="section level2">
<h2><span class="header-section-number">7.5</span> Selecting predictors</h2>
<p>When there are many possible predictors, we need some strategy for selecting the best predictors to use in a regression model. Here we use predictive accuracy. They can be shown using the <code>glance()</code> function, here applied to the model for <code>us_change</code>:</p>
<div class="sourceCode" id="cb136"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb136-1"><a href="time-series-regression-models.html#cb136-1"></a><span class="kw">glance</span>(us_change_mfit) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb136-2"><a href="time-series-regression-models.html#cb136-2"></a><span class="st">  </span><span class="kw">select</span>(adj_r_squared, CV, AIC, AICc, BIC)</span>
<span id="cb136-3"><a href="time-series-regression-models.html#cb136-3"></a><span class="co">#&gt; # A tibble: 1 x 5</span></span>
<span id="cb136-4"><a href="time-series-regression-models.html#cb136-4"></a><span class="co">#&gt;   adj_r_squared    CV   AIC  AICc   BIC</span></span>
<span id="cb136-5"><a href="time-series-regression-models.html#cb136-5"></a><span class="co">#&gt;           &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt; &lt;dbl&gt;</span></span>
<span id="cb136-6"><a href="time-series-regression-models.html#cb136-6"></a><span class="co">#&gt; 1         0.763 0.104 -457. -456. -437.</span></span></code></pre></div>
<div id="adjusst-r-square" class="section level3">
<h3><span class="header-section-number">7.5.1</span> Adjusst R square</h3>
<p>The determinant coefficient, <span class="math inline">\(R^2\)</span>, is defined by</p>
<p><span class="math display">\[
R^2 = \frac{\sum{(\hat{y}_t - \bar{y}_t)^2}}{\sum{(y_t - \bar{y}_t)^2}}
\]</span></p>
<p>Since <span class="math inline">\(R^2\)</span> favours (unjustly) models with more predictors (increases whatever predictor is added), it is common to use a penalized version, Adjusted <span class="math inline">\(R^2\)</span> or <span class="math inline">\(\bar{R}^2\)</span></p>
<p><span class="math display">\[
\bar{R}^2 = 1 - (1 - R^2)\frac{T - 1}{T - k -1}
\]</span></p>
<p>All things being equal, adjusted <span class="math inline">\(R^2\)</span> is generally smaller than <span class="math inline">\(R^2\)</span>, unless you are dealing with a null model so that <span class="math inline">\(k = 0\)</span>, since it aims to penalize models with too many predictors.</p>
<p>Using this measure, the best model will be the one with the largest value of ¯R2. Maximising ¯R2 is equivalent to minimising the standard error <span class="math inline">\(\hat{\sigma}\)</span> of <span class="math inline">\(\hat{\varepsilon}\)</span> given in Equation <a href="time-series-regression-models.html#eq:standard-error">(7.3)</a>.<br />
Maximising <span class="math inline">\(\bar{R}^2\)</span> (For the rest of regression measurements, we almost always want to minimize) works quite well as a method of selecting predictors, although it does tend to err on the side of selecting too many predictors.</p>
</div>
<div id="cross-validation" class="section level3">
<h3><span class="header-section-number">7.5.2</span> Cross validation</h3>
<p>Time series cross-validation was introduced in Section <a href="the-forecasters-toolbox.html#time-series-cross-validation">5.7</a> as a general tool for determining the predictive ability of a model. For regression models, it is also possible to use <strong>classical leave-one-out cross-validation</strong> to selection predictors. This is faster and makes more efficient use of the data. The procedure uses the following steps:</p>
<ol style="list-style-type: decimal">
<li><p>Remove observation t from the data set, and fit the model using the remaining data. Then compute the error (<span class="math inline">\(e^*_t=y_t−\hat{y}_t\)</span>) for the omitted observation.</p></li>
<li><p>Repeat step 1 for <span class="math inline">\(t = 1, 2, \dots, T\)</span></p></li>
<li><p>Compute <span class="math inline">\(MSE = \sum{{e^*_t}^2} / T\)</span> , we shall call it the <strong>CV</strong>.</p></li>
</ol>
<p>Although cross validation may look like time-consuming procedure, there are fast methods of calculating CV, so that it takes no longer than fitting one model to the full data set. The equation for computing CV efficiently is given in Section <a href="time-series-regression-models.html#matrix-formulation">7.7</a>. Under this criterion, the best model is the one with the smallest value of CV.</p>
</div>
<div id="akaikes-information-criterion" class="section level3">
<h3><span class="header-section-number">7.5.3</span> Akaike’s Information Criterion</h3>
<p>A closely-related method is Akaike’s Information Criterion, which we define as</p>
<p><span class="math display">\[
\text{AIC} = T \log{\frac{SSE}{T}} + 2(K + 2)
\]</span>
The k+2 part of the equation occurs because there are k+2 parameters in the model: the k coefficients for the predictors, the intercept and the variance of the residuals. The idea here is to penalise the fit of the model (SSE) with the number of parameters that need to be estimated.</p>
<p>The model with the minimum value of the AIC is often the best model for forecasting. For large values of <span class="math inline">\(T\)</span>, minimising the AIC is equivalent to minimising the CV value.</p>
<p><strong>For small values of <span class="math inline">\(T\)</span>, the AIC tends to select too many predictors</strong>, and so a bias-corrected version of the AIC has been developed</p>
<p><span class="math display">\[
\text{AIC}_c = \text{AIC} +  \frac{2(k + 2)(k + 3)}{T - k - 3}
\]</span></p>
</div>
<div id="bayesian-information-criterion" class="section level3">
<h3><span class="header-section-number">7.5.4</span> Bayesian Information Criterion</h3>
<p>A related measure is Schwarz’s Bayesian Information Criterion (usually abbreviated to BIC, SBIC or SC):</p>
<p><span class="math display">\[
\text{BIC} = T\log{(\frac{SSE}{T}) + (k + 2)\log{(T)}}
\]</span>
As with the AIC, minimising the BIC is intended to give the best model. The model chosen by the BIC is either the same as that chosen by the AIC, or one with fewer terms. This is because the <strong>BIC penalises the number of parameters more heavily than the AIC</strong>. For large values of T, minimising BIC is similar to leave-v-out cross-validation when <span class="math inline">\(v = T[1 - 1/\log{(T)} -1]\)</span></p>
</div>
<div id="which-measure-should-we-suse" class="section level3">
<h3><span class="header-section-number">7.5.5</span> Which measure should we suse</h3>
<p>While <span class="math inline">\(\bar{R}^2\)</span> is widely used, and has been around longer than the other measures, <strong>its tendency to select too many predictor variables makes it less suitable for forecasting</strong>.</p>
<p>Many statisticians like to use the BIC because it has the feature that if there is a true underlying model, the BIC will select that model given enough data. <strong>However</strong>, in reality, there is rarely, if ever, a true underlying model, and even if there was a true underlying model, selecting that model will not necessarily give the best forecasts (because the parameter estimates may not be accurate).</p>
<p>Consequently, <strong>we recommend that one of the <span class="math inline">\(\text{AIC}_c\)</span>, <span class="math inline">\(\text{AIC}\)</span>, or <span class="math inline">\(\text{CV}\)</span> statistics be used</strong>, each of which has forecasting as their objective. If the value of <span class="math inline">\(T\)</span> is large enough, they will all lead to the same model. In most of the examples in this book, we use the <span class="math inline">\(\text{AIC}_c\)</span> value to select the forecasting model.</p>
</div>
<div id="example-us-consumption" class="section level3">
<h3><span class="header-section-number">7.5.6</span> Example: US consumption</h3>
<p>In <code>us_change_mfit</code> 4 predictors are specified, so there are <span class="math inline">\(2^4 = 16\)</span> possible models</p>
<p><img src="images/all_subsets.png" width="100%" style="display: block; margin: auto;" /></p>
<p>The best model contains all four predictors according to <span class="math inline">\(\text{AIC}_c\)</span>. The results from a backward selection using AIC follow suit:</p>
<div class="sourceCode" id="cb137"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb137-1"><a href="time-series-regression-models.html#cb137-1"></a>MASS<span class="op">::</span><span class="kw">stepAIC</span>(us_change_lm, <span class="dt">direction =</span> <span class="st">&quot;backward&quot;</span>)</span>
<span id="cb137-2"><a href="time-series-regression-models.html#cb137-2"></a><span class="co">#&gt; Start:  AIC=-458.58</span></span>
<span id="cb137-3"><a href="time-series-regression-models.html#cb137-3"></a><span class="co">#&gt; Consumption ~ Income + Production + Savings + Unemployment</span></span>
<span id="cb137-4"><a href="time-series-regression-models.html#cb137-4"></a><span class="co">#&gt; </span></span>
<span id="cb137-5"><a href="time-series-regression-models.html#cb137-5"></a><span class="co">#&gt;                Df Sum of Sq    RSS     AIC</span></span>
<span id="cb137-6"><a href="time-series-regression-models.html#cb137-6"></a><span class="co">#&gt; &lt;none&gt;                      18.573 -458.58</span></span>
<span id="cb137-7"><a href="time-series-regression-models.html#cb137-7"></a><span class="co">#&gt; - Unemployment  1     0.322 18.895 -457.18</span></span>
<span id="cb137-8"><a href="time-series-regression-models.html#cb137-8"></a><span class="co">#&gt; - Production    1     0.400 18.973 -456.36</span></span>
<span id="cb137-9"><a href="time-series-regression-models.html#cb137-9"></a><span class="co">#&gt; - Savings       1    31.483 50.056 -264.27</span></span>
<span id="cb137-10"><a href="time-series-regression-models.html#cb137-10"></a><span class="co">#&gt; - Income        1    32.799 51.371 -259.14</span></span>
<span id="cb137-11"><a href="time-series-regression-models.html#cb137-11"></a><span class="co">#&gt; </span></span>
<span id="cb137-12"><a href="time-series-regression-models.html#cb137-12"></a><span class="co">#&gt; Call:</span></span>
<span id="cb137-13"><a href="time-series-regression-models.html#cb137-13"></a><span class="co">#&gt; lm(formula = Consumption ~ Income + Production + Savings + Unemployment, </span></span>
<span id="cb137-14"><a href="time-series-regression-models.html#cb137-14"></a><span class="co">#&gt;     data = us_change)</span></span>
<span id="cb137-15"><a href="time-series-regression-models.html#cb137-15"></a><span class="co">#&gt; </span></span>
<span id="cb137-16"><a href="time-series-regression-models.html#cb137-16"></a><span class="co">#&gt; Coefficients:</span></span>
<span id="cb137-17"><a href="time-series-regression-models.html#cb137-17"></a><span class="co">#&gt;  (Intercept)        Income    Production       Savings  Unemployment  </span></span>
<span id="cb137-18"><a href="time-series-regression-models.html#cb137-18"></a><span class="co">#&gt;      0.25311       0.74058       0.04717      -0.05289      -0.17469</span></span></code></pre></div>
<p>The best model contains all four predictors. However, a closer look at the results reveals some interesting features. There is clear separation between the models in the first four rows and the ones below. This indicates that <code>Income</code> and <code>Savings</code> are both more important variables than <code>Production</code> and <code>Unemployment</code>. Also, the first three rows have almost identical values of <span class="math inline">\(\text{CV}\)</span>, <span class="math inline">\(\text{AIC}\)</span> and <span class="math inline">\(\text{AIC}_c\)</span>. So we could possibly drop either the <code>Production</code> variable, or the <code>Unemployment</code> variable, and get similar forecasts. Note that Production and Unemployment are highly (negatively) correlated (<span class="math inline">\(\hat{r} = -0.768\)</span>, see figure <a href="time-series-regression-models.html#fig:pairs">7.1</a>)</p>
</div>
</div>
<div id="forecasting-with-regression" class="section level2">
<h2><span class="header-section-number">7.6</span> Forecasting with regression</h2>
<p>Recall the regression model Equation <a href="time-series-regression-models.html#eq:multiple-linear-reg">(7.1)</a></p>
<p><span class="math display">\[\begin{equation}
y_t = \beta_0 + \beta_1x_{1t} + \beta_2x_{2t} + \dots + \beta_kx_{kt} + \varepsilon_t
\end{equation}\]</span></p>
<p>While we can easily get fitted values <span class="math inline">\({\hat{y}_1, \hat{y}_2, \dots, \hat{y}_T}\)</span>, what we are interested in here, however, is forecasting future values of <span class="math inline">\(y\)</span>.</p>
<div id="ex-ante-versus-ex-post-forecasts" class="section level3">
<h3><span class="header-section-number">7.6.1</span> Ex-ante versus ex-post forecasts</h3>
<p>When using regression models for time series data, we need to distinguish between the different types of forecasts that can be produced, depending on whether future values of <strong>predictor variables</strong> are known in advance, or whether we need to forecast predcitor variables first.</p>
<p><strong>Ex-ante forecast</strong> is a forecast based solely on information available at the time of the forecast, whereas <strong>ex-post</strong> forecast is a forecast that uses information beyond the time at which the forecast is made.</p>
<p>For example, ex-ante forecasts for the percentage change in US consumption will first requires forecasts of the predictors. To obtain these we can use one of the simple methods introduced in Section <a href="the-forecasters-toolbox.html#some-simple-forecasting-methods">5.2</a> (mean, naive, seasonal navie and drift method) or more sophisticated pure time series approaches that follow in Chapters <a href="exponential-smoothing.html#exponential-smoothing">8</a> and <a href="arima-models.html#arima-models">10</a>. Alternatively, forecasts from some other source, such as a government agency, may be available and can be used. Ex-ante forecasts are genuine forecasting.</p>
<p>On the other hand, ex-post forecasts are those that are made using later information on the predictors. For example, ex-post forecasts of consumption may use the actual observations of the predictors, once these have been observed. These are not genuine forecasts, but are useful for studying the behaviour of forecasting models.</p>
</div>
<div id="example-australian-quarterly-beer-production-1" class="section level3">
<h3><span class="header-section-number">7.6.2</span> Example: Australian quarterly beer production</h3>
<p>Normally, we cannot use actual future values of the predictor variables when producing ex-ante forecasts because their values will not be known in advance. However, the special predictors introduced in Section <a href="time-series-regression-models.html#some-useful-predictors">7.4</a> are all known in advance (a trend variable and 3 seasonal dummy variable), as they are based on calendar variables (e.g., seasonal dummy variables or public holiday indicators) or deterministic functions of time (e.g. time trend). In such cases, there is no difference between ex-ante and ex-post forecasts.</p>
<div class="sourceCode" id="cb138"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb138-1"><a href="time-series-regression-models.html#cb138-1"></a><span class="co"># `beer_fit` uses only trend variabe and seasonal dummy variables. In such cases, there is no difference between ex-ante and ex-post forecasts. </span></span>
<span id="cb138-2"><a href="time-series-regression-models.html#cb138-2"></a>beer_fit <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb138-3"><a href="time-series-regression-models.html#cb138-3"></a><span class="st">  </span><span class="kw">forecast</span>(<span class="dt">h =</span> <span class="st">&quot;3 years&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb138-4"><a href="time-series-regression-models.html#cb138-4"></a><span class="st">  </span><span class="kw">autoplot</span>(recent_production, <span class="dt">level =</span> <span class="dv">90</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb138-5"><a href="time-series-regression-models.html#cb138-5"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">x =</span> <span class="st">&quot;Year&quot;</span>, <span class="dt">y =</span> <span class="st">&quot;megalitres&quot;</span>,</span>
<span id="cb138-6"><a href="time-series-regression-models.html#cb138-6"></a>       <span class="dt">title =</span> <span class="st">&quot;Forecasts of beer production using regression&quot;</span>)</span></code></pre></div>
<p><img src="ch7_files/figure-html/unnamed-chunk-33-1.png" width="100%" style="display: block; margin: auto;" /></p>
</div>
<div id="scenario-based-forecasting" class="section level3">
<h3><span class="header-section-number">7.6.3</span> Scenario based forecasting</h3>
<p>In this setting, the forecaster assumes possible scenarios for the predictor variables that are of interest. For example, a US policy maker may be interested in comparing the predicted change in consumption when there is a constant growth of <span class="math inline">\(1\%\)</span> and <span class="math inline">\(0.5\%\)</span> respectively for income and savings with no change in production and the employment rate, versus a respective decline of <span class="math inline">\(1\%\)</span> and <span class="math inline">\(0.5\%\)</span>, for each of the four quarters following the end of the sample.</p>
<p>We should note that prediction intervals for scenario based forecasts <strong>do not include the uncertainty associated with the future values of the predictor variables</strong>. They assume that the values of the predictors are known in advance, (i.e, ex-post forecasts).</p>
<div class="sourceCode" id="cb139"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb139-1"><a href="time-series-regression-models.html#cb139-1"></a><span class="co"># new_data(data, n) creates n rows of time index of each series to</span></span>
<span id="cb139-2"><a href="time-series-regression-models.html#cb139-2"></a><span class="kw">new_data</span>(us_change, <span class="dv">4</span>)</span>
<span id="cb139-3"><a href="time-series-regression-models.html#cb139-3"></a><span class="co">#&gt; # A tsibble: 4 x 1 [1Q]</span></span>
<span id="cb139-4"><a href="time-series-regression-models.html#cb139-4"></a><span class="co">#&gt;   Quarter</span></span>
<span id="cb139-5"><a href="time-series-regression-models.html#cb139-5"></a><span class="co">#&gt;     &lt;qtr&gt;</span></span>
<span id="cb139-6"><a href="time-series-regression-models.html#cb139-6"></a><span class="co">#&gt; 1 2019 Q3</span></span>
<span id="cb139-7"><a href="time-series-regression-models.html#cb139-7"></a><span class="co">#&gt; 2 2019 Q4</span></span>
<span id="cb139-8"><a href="time-series-regression-models.html#cb139-8"></a><span class="co">#&gt; 3 2020 Q1</span></span>
<span id="cb139-9"><a href="time-series-regression-models.html#cb139-9"></a><span class="co">#&gt; 4 2020 Q2</span></span>
<span id="cb139-10"><a href="time-series-regression-models.html#cb139-10"></a></span>
<span id="cb139-11"><a href="time-series-regression-models.html#cb139-11"></a><span class="co"># define a function producing values based on increase / decrease rate </span></span>
<span id="cb139-12"><a href="time-series-regression-models.html#cb139-12"></a>new_obs &lt;-<span class="st"> </span><span class="cf">function</span>(value, length, rate) {</span>
<span id="cb139-13"><a href="time-series-regression-models.html#cb139-13"></a>  vec &lt;-<span class="st"> </span><span class="kw">rep</span>(value, length)</span>
<span id="cb139-14"><a href="time-series-regression-models.html#cb139-14"></a>  <span class="kw">imap_dbl</span>(vec, <span class="op">~</span><span class="st"> </span>.x <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">+</span><span class="st"> </span>rate) <span class="op">^</span><span class="st"> </span>.y)</span>
<span id="cb139-15"><a href="time-series-regression-models.html#cb139-15"></a>}</span>
<span id="cb139-16"><a href="time-series-regression-models.html#cb139-16"></a></span>
<span id="cb139-17"><a href="time-series-regression-models.html#cb139-17"></a>up_future &lt;-<span class="st"> </span>us_change <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb139-18"><a href="time-series-regression-models.html#cb139-18"></a><span class="st">  </span><span class="kw">slice</span>(<span class="kw">n</span>()) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb139-19"><a href="time-series-regression-models.html#cb139-19"></a><span class="st">  </span><span class="kw">as_tibble</span>() <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb139-20"><a href="time-series-regression-models.html#cb139-20"></a><span class="st">  </span><span class="kw">select</span>(<span class="dv">3</span><span class="op">:</span><span class="dv">6</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb139-21"><a href="time-series-regression-models.html#cb139-21"></a><span class="st">  </span><span class="kw">pivot_longer</span>(<span class="kw">everything</span>()) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb139-22"><a href="time-series-regression-models.html#cb139-22"></a><span class="st">  </span><span class="kw">select</span>(<span class="op">-</span>name) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb139-23"><a href="time-series-regression-models.html#cb139-23"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">length =</span> <span class="dv">4</span>, <span class="dt">rate =</span> <span class="kw">c</span>(<span class="fl">0.01</span>, <span class="dv">0</span>, <span class="fl">0.005</span>, <span class="dv">0</span>)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb139-24"><a href="time-series-regression-models.html#cb139-24"></a><span class="st">  </span><span class="kw">pmap</span>(new_obs) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb139-25"><a href="time-series-regression-models.html#cb139-25"></a><span class="st">  </span><span class="kw">set_names</span>(<span class="kw">c</span>(<span class="st">&quot;Income&quot;</span>, <span class="st">&quot;Production&quot;</span>, <span class="st">&quot;Savings&quot;</span>, <span class="st">&quot;Unemployment&quot;</span>)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb139-26"><a href="time-series-regression-models.html#cb139-26"></a><span class="st">  </span><span class="kw">as_tibble</span>() <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb139-27"><a href="time-series-regression-models.html#cb139-27"></a><span class="st">  </span><span class="kw">bind_cols</span>(<span class="kw">new_data</span>(us_change, <span class="dv">4</span>), .)</span>
<span id="cb139-28"><a href="time-series-regression-models.html#cb139-28"></a>   </span>
<span id="cb139-29"><a href="time-series-regression-models.html#cb139-29"></a>up_future</span>
<span id="cb139-30"><a href="time-series-regression-models.html#cb139-30"></a><span class="co">#&gt; # A tsibble: 4 x 5 [1Q]</span></span>
<span id="cb139-31"><a href="time-series-regression-models.html#cb139-31"></a><span class="co">#&gt;   Quarter Income Production Savings Unemployment</span></span>
<span id="cb139-32"><a href="time-series-regression-models.html#cb139-32"></a><span class="co">#&gt;     &lt;qtr&gt;  &lt;dbl&gt;      &lt;dbl&gt;   &lt;dbl&gt;        &lt;dbl&gt;</span></span>
<span id="cb139-33"><a href="time-series-regression-models.html#cb139-33"></a><span class="co">#&gt; 1 2019 Q3  0.599     -0.540   -4.29       -0.100</span></span>
<span id="cb139-34"><a href="time-series-regression-models.html#cb139-34"></a><span class="co">#&gt; 2 2019 Q4  0.605     -0.540   -4.31       -0.100</span></span>
<span id="cb139-35"><a href="time-series-regression-models.html#cb139-35"></a><span class="co">#&gt; 3 2020 Q1  0.611     -0.540   -4.33       -0.100</span></span>
<span id="cb139-36"><a href="time-series-regression-models.html#cb139-36"></a><span class="co">#&gt; 4 2020 Q2  0.617     -0.540   -4.35       -0.100</span></span>
<span id="cb139-37"><a href="time-series-regression-models.html#cb139-37"></a></span>
<span id="cb139-38"><a href="time-series-regression-models.html#cb139-38"></a>down_future &lt;-<span class="st"> </span>us_change <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb139-39"><a href="time-series-regression-models.html#cb139-39"></a><span class="st">  </span><span class="kw">slice</span>(<span class="kw">n</span>()) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb139-40"><a href="time-series-regression-models.html#cb139-40"></a><span class="st">  </span><span class="kw">as_tibble</span>() <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb139-41"><a href="time-series-regression-models.html#cb139-41"></a><span class="st">  </span><span class="kw">select</span>(<span class="dv">3</span><span class="op">:</span><span class="dv">6</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb139-42"><a href="time-series-regression-models.html#cb139-42"></a><span class="st">  </span><span class="kw">pivot_longer</span>(<span class="kw">everything</span>()) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb139-43"><a href="time-series-regression-models.html#cb139-43"></a><span class="st">  </span><span class="kw">select</span>(<span class="op">-</span>name) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb139-44"><a href="time-series-regression-models.html#cb139-44"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">length =</span> <span class="dv">4</span>, <span class="dt">rate =</span> <span class="kw">c</span>(<span class="op">-</span><span class="fl">0.01</span>, <span class="dv">0</span>, <span class="fl">-0.005</span>, <span class="dv">0</span>)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb139-45"><a href="time-series-regression-models.html#cb139-45"></a><span class="st">  </span><span class="kw">pmap</span>(new_obs) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb139-46"><a href="time-series-regression-models.html#cb139-46"></a><span class="st">  </span><span class="kw">set_names</span>(<span class="kw">c</span>(<span class="st">&quot;Income&quot;</span>, <span class="st">&quot;Production&quot;</span>, <span class="st">&quot;Savings&quot;</span>, <span class="st">&quot;Unemployment&quot;</span>)) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb139-47"><a href="time-series-regression-models.html#cb139-47"></a><span class="st">  </span><span class="kw">as_tibble</span>() <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb139-48"><a href="time-series-regression-models.html#cb139-48"></a><span class="st">  </span><span class="kw">bind_cols</span>(<span class="kw">new_data</span>(us_change, <span class="dv">4</span>), .)  </span>
<span id="cb139-49"><a href="time-series-regression-models.html#cb139-49"></a></span>
<span id="cb139-50"><a href="time-series-regression-models.html#cb139-50"></a>down_future</span>
<span id="cb139-51"><a href="time-series-regression-models.html#cb139-51"></a><span class="co">#&gt; # A tsibble: 4 x 5 [1Q]</span></span>
<span id="cb139-52"><a href="time-series-regression-models.html#cb139-52"></a><span class="co">#&gt;   Quarter Income Production Savings Unemployment</span></span>
<span id="cb139-53"><a href="time-series-regression-models.html#cb139-53"></a><span class="co">#&gt;     &lt;qtr&gt;  &lt;dbl&gt;      &lt;dbl&gt;   &lt;dbl&gt;        &lt;dbl&gt;</span></span>
<span id="cb139-54"><a href="time-series-regression-models.html#cb139-54"></a><span class="co">#&gt; 1 2019 Q3  0.587     -0.540   -4.24       -0.100</span></span>
<span id="cb139-55"><a href="time-series-regression-models.html#cb139-55"></a><span class="co">#&gt; 2 2019 Q4  0.582     -0.540   -4.22       -0.100</span></span>
<span id="cb139-56"><a href="time-series-regression-models.html#cb139-56"></a><span class="co">#&gt; 3 2020 Q1  0.576     -0.540   -4.20       -0.100</span></span>
<span id="cb139-57"><a href="time-series-regression-models.html#cb139-57"></a><span class="co">#&gt; 4 2020 Q2  0.570     -0.540   -4.18       -0.100</span></span></code></pre></div>
<p>Then we could produce forecast for each of the two scenarios :</p>
<div class="sourceCode" id="cb140"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb140-1"><a href="time-series-regression-models.html#cb140-1"></a>up_future_fc &lt;-<span class="st"> </span><span class="kw">forecast</span>(us_change_mfit, <span class="dt">new_data =</span> up_future) <span class="op">%&gt;%</span></span>
<span id="cb140-2"><a href="time-series-regression-models.html#cb140-2"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Scenario =</span> <span class="st">&quot;Increase&quot;</span>) </span>
<span id="cb140-3"><a href="time-series-regression-models.html#cb140-3"></a></span>
<span id="cb140-4"><a href="time-series-regression-models.html#cb140-4"></a>down_future_fc &lt;-<span class="st"> </span><span class="kw">forecast</span>(us_change_mfit, <span class="dt">new_data =</span> down_future) <span class="op">%&gt;%</span></span>
<span id="cb140-5"><a href="time-series-regression-models.html#cb140-5"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Scenario =</span> <span class="st">&quot;Decrease&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb140-6"><a href="time-series-regression-models.html#cb140-6"></a><span class="st">  </span><span class="kw">as_tibble</span>()</span>
<span id="cb140-7"><a href="time-series-regression-models.html#cb140-7"></a></span>
<span id="cb140-8"><a href="time-series-regression-models.html#cb140-8"></a>us_change <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb140-9"><a href="time-series-regression-models.html#cb140-9"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(Quarter, Consumption)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb140-10"><a href="time-series-regression-models.html#cb140-10"></a><span class="st">  </span><span class="kw">geom_line</span>() <span class="op">+</span><span class="st"> </span></span>
<span id="cb140-11"><a href="time-series-regression-models.html#cb140-11"></a><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">y =</span> .mean), <span class="dt">data =</span> up_future_fc, <span class="dt">color =</span> <span class="st">&quot;red&quot;</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb140-12"><a href="time-series-regression-models.html#cb140-12"></a><span class="st">  </span><span class="kw">geom_line</span>(<span class="kw">aes</span>(<span class="dt">y =</span> .mean), <span class="dt">data =</span> down_future_fc, <span class="dt">color =</span> <span class="st">&quot;blue&quot;</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb140-13"><a href="time-series-regression-models.html#cb140-13"></a><span class="st">  </span><span class="kw">coord_cartesian</span>(<span class="dt">xlim =</span> <span class="kw">c</span>(<span class="kw">ymd</span>(<span class="st">&quot;2015-01-01&quot;</span>, <span class="ot">NA</span>)),</span>
<span id="cb140-14"><a href="time-series-regression-models.html#cb140-14"></a>                  <span class="dt">ylim =</span> <span class="kw">c</span>(<span class="dv">0</span>, <span class="fl">1.2</span>))</span></code></pre></div>
<p><img src="ch7_files/figure-html/unnamed-chunk-35-1.png" width="100%" style="display: block; margin: auto;" /></p>
</div>
<div id="prediction-intervals" class="section level3">
<h3><span class="header-section-number">7.6.4</span> Prediction intervals</h3>
<p>The general formulation of how to calculate prediction intervals for multiple regression models is presented in Section <a href="time-series-regression-models.html#matrix-formulation">7.7</a>. As this involves some advanced matrix algebra we present here the case for calculating prediction intervals for a simple regression, where a forecast can be generated using the equation</p>
<p><span class="math display">\[
\hat{y} = \hat{\beta}_0 + \hat{\beta}_1 x
\]</span></p>
<p>Assuming that the regression errors are normally distributed, an approximate <span class="math inline">\(1 - \alpha\)</span> prediction interval associated with this forecast is given by</p>
<p><span class="math display" id="eq:prediction-interval">\[\begin{equation}
\tag{7.4}
\hat{y} + Z_{\alpha}\hat{\sigma} \sqrt{1 + \frac{1}{T} + \frac{(x - \bar{x})^2}{(T - 1)s_x^2}}
\end{equation}\]</span></p>
<p>where <span class="math inline">\(\hat{\sigma}\)</span> is the residual standard deviation given by Equation <a href="time-series-regression-models.html#eq:standard-error">(7.3)</a>, and <span class="math inline">\(s_x\)</span> the standard deviation of predictor <span class="math inline">\(x\)</span>.</p>
<p>Equation (eq:prediction-interval) shows that the prediction interval is wider when <span class="math inline">\(x\)</span> is far from <span class="math inline">\(\bar{x}\)</span>. That is, <strong>we are more certain about our forecasts when considering values of the predictor variable close to its sample mean</strong>.</p>
</div>
<div id="building-a-predictive-regression-model" class="section level3">
<h3><span class="header-section-number">7.6.5</span> Building a predictive regression model</h3>
<p>A major challenge however in regression, is that in order to generate ex-ante forecasts, the model requires future values of each predictor. If scenario based forecasting is of interest then these models are extremely useful. However, if ex-ante forecasting is the main focus, obtaining forecasts of the predictors can be challenging (in many cases generating forecasts for the predictor variables can be more challenging than forecasting directly the forecast variable without using predictors).</p>
<p>An alternative formulation is to use as predictors their lagged values. Assuming that we are interested in generating a <span class="math inline">\(h\)</span>-step ahead forecast we write</p>
<p><span class="math display">\[
y_{t + h} = \beta_0 + \beta_1 x_{1t} +  \beta_2 x_{2t} + \cdots  + \beta_k x_{kt}
\]</span></p>
<p>for <span class="math inline">\(h = 1, 2, \dots\)</span>. The predictor set is formed by values of the <span class="math inline">\(x\)</span>s that are observed h time periods prior to observing y. Therefore when the estimated model is projected into the future, i.e., beyond the end of the sample <span class="math inline">\(T\)</span>, all predictor values are available (unless the step of forecast is larger than lag <span class="math inline">\(h\)</span>).</p>
<p>Including lagged values of the predictors does not only make the model operational for easily generating forecasts, it also makes it intuitively appealing. For example, the effect of a policy change with the aim of increasing production may not have an instantaneous effect on consumption expenditure. It is most likely that this will happen with a lagging effect. We touched upon this in Section <a href="time-series-regression-models.html#some-useful-predictors">7.4</a> when briefly introducing distributed lags as predictors. Several directions for generalising regression models to better incorporate the rich dynamics observed in time series are discussed in Chapter <a href="dynamic-regression-models.html#dynamic-regression-models">11</a>.</p>
</div>
</div>
<div id="matrix-formulation" class="section level2">
<h2><span class="header-section-number">7.7</span> Matrix formulation</h2>
<p>A linear regression model can be expressed in matrix forms as such:</p>
<p><span class="math display">\[
\boldsymbol{y} = \boldsymbol{X} \boldsymbol{\beta} + \boldsymbol{\varepsilon}
\]</span></p>
<p>where <span class="math inline">\(\boldsymbol{y} = [y_1, y_2, \dots, y_T]\)</span>, <span class="math inline">\(\boldsymbol{X}\)</span> being the design matrix and <span class="math inline">\(\boldsymbol{\varepsilon} = [\varepsilon_1, \varepsilon_2, \dots, \varepsilon_T]\)</span> thus have mean <span class="math inline">\(\boldsymbol{0}\)</span> and variance-covariance matrix <span class="math inline">\(\sigma^2\boldsymbol{I}\)</span></p>
<p>Least square estimation uses a projection matrix <span class="math inline">\(H = \boldsymbol{X(X^TX)^{-1}X^T}\)</span> (also called “hat matrix”) so that <span class="math inline">\(\boldsymbol{Hy = \hat{y} = X\hat{\beta}}\)</span>. We can derive that</p>
<p><span class="math display">\[
\boldsymbol{\beta} = \boldsymbol{(X^TX)^{-1}X^Ty}
\]</span></p>
<p>The residual variance <span class="math inline">\(\hat{\sigma}\)</span>is estimated using :</p>
<p><span class="math display">\[
\boldsymbol{\hat{\sigma}} = \frac{1}{T-k-1}\boldsymbol{(y - X\hat{\beta})^T(y - X\hat{\beta})}
\]</span></p>
<p>If the diagonal value of <span class="math inline">\(\boldsymbol{P}\)</span> is denoted by <span class="math inline">\(h_1, h_2 , \dots, h_T\)</span> then the cross-validation statistic can be computed using :</p>
<p><span class="math display">\[
\text{CV} = \frac{1}{T}\sum{[e_t / (1 - h_t)]^2}
\]</span></p>
<p>For any given <span class="math inline">\(\boldsymbol{x^*} = [1, x_{1t}, \dots, x_{kt}]\)</span>, the fitted value is <span class="math inline">\(\hat{y} = \boldsymbol{x^*}\boldsymbol{\hat{\beta}}\)</span> and its estimated variance given by:</p>
<p><span class="math display">\[
\hat{\sigma}[1 + \boldsymbol{x^*}(\boldsymbol{X^T X})^{-1}\boldsymbol{(x^*)^T}]
\]</span></p>
<p>A <span class="math inline">\(1 - \alpha\)</span> prediction interval (assuming normally distributed errors) can be calculated as</p>
<p><span class="math display">\[
\hat{y} + Z_\alpha \hat{\sigma} \sqrt{[1 + \boldsymbol{x^*}(\boldsymbol{X^T X})^{-1}\boldsymbol{(x^*)^T}]}
\]</span></p>
<p>This takes into account the uncertainty due to the error term <span class="math inline">\(\boldsymbol{\varepsilon}\)</span> and the uncertainty in the coefficient estimates. However, it ignores any errors in <span class="math inline">\(\boldsymbol{x^*}\)</span>. Thus, if the future values of the predictors are uncertain, then the prediction interval calculated using this expression will be too narrow.</p>
</div>
<div id="nonlinear-regression" class="section level2">
<h2><span class="header-section-number">7.8</span> Nonlinear regression</h2>
<p>Although the linear relationship assumed so far in this chapter is often adequate, there are many cases in which a nonlinear functional form is more suitable. To keep things simple in this section we assume that we only have one predictor <span class="math inline">\(x\)</span>.</p>
<p>The simplest way of modelling a nonlinear relationship is to transform the forecast variable y and/or the predictor variable x before estimating a regression model. While this provides a non-linear functional form, the model is still linear in the parameters. The most commonly used transformation is the (natural) logarithm (see Section <a href="time-series-decomposition.html#transformation-and-adjustments">3.1</a>).</p>
<p>A <strong>log-log</strong> functional form is specified as
<span class="math display">\[
\log{y} = \beta_0 + \beta_1 \log{x} + \varepsilon
\]</span></p>
<p>Other useful forms can also be specified. The <strong>log-linear</strong> form is specified by only transforming the forecast variable and the <strong>linear-log</strong> form is obtained by transforming the predictor.</p>
<p>Recall that in order to perform a logarithmic transformation to a variable, all of its observed values must be greater than zero. In the case that variable <span class="math inline">\(x\)</span> contains zeros, we use the transformation <span class="math inline">\(\log{(x+1)}\)</span>; i.e., we add one to the value of the variable and then take logarithms. This has a similar effect to taking logarithms but avoids the problem of zeros. It also has the neat side-effect of zeros on the original scale remaining zeros on the transformed scale.</p>
<p>Also, box-cox transformation as a family of both power transformation and log transformation is given by Equation <a href="time-series-decomposition.html#eq:box-cox">(3.1)</a></p>
<p>There are cases for which simply transforming the data will not be adequate and a more general specification may be required. Then the model we use is</p>
<p><span class="math display">\[
y = f(x) + \varepsilon
\]</span></p>
<p>where <span class="math inline">\(f(x)\)</span> could be of any form. In the specification of nonlinear regression that follows, we allow f to be a more flexible nonlinear function of <span class="math inline">\(x\)</span>, compared to simply a logarithmic or other transformation.</p>
<p>One of the simplest specifications is to make <span class="math inline">\(f\)</span> <strong>piecewise linear</strong>. That is, we introduce points where the slope of <span class="math inline">\(f\)</span> can change. These points are called <strong>knots</strong>. This can be achieved by letting <span class="math inline">\(x_{1t} = x\)</span> and introducing variable <span class="math inline">\(x_{2t}\)</span> such that</p>
<p><span class="math display">\[
x_{2t} = (x - c)_+ = 
\begin{cases} 
0 &amp; x &lt; c\\
(x - c) &amp; x \ge c
\end{cases}
\]</span></p>
<p>The notation <span class="math inline">\((x - c)_+\)</span> means that the value <span class="math inline">\(x - c\)</span> if it is positive and <span class="math inline">\(0\)</span> ohterwise, which can be achieved by introducing a dummy variable <span class="math inline">\(D\)</span> that take 0 if <span class="math inline">\(x &lt; 0\)</span> and 1 if <span class="math inline">\(x \ge 0\)</span> and then include term <span class="math inline">\((x - c)\times D\)</span>. This forces the slope to bend at point <span class="math inline">\(c\)</span>. Additional bends can be included in the relationship by adding further variables of the above form.</p>
<p>Piecewise linear relationships constructed in this way are a special case of regression splines. In general, a linear regression spline is obtained using</p>
<p><span class="math display">\[
x_1 = x \;\;\; x_2 = (x - c_1)_+ \;\;\; \cdots \;\;\; x_k = (x - c_{k-1})_+
\]</span></p>
<p>where <span class="math inline">\(c_1, \dots, c_k-1\)</span> are knots. Selecting the number of knots (<span class="math inline">\(k−1\)</span>) and where they should be positioned can be difficult and somewhat arbitrary.</p>
<div id="forecasting-with-a-nonlinear-trend" class="section level3">
<h3><span class="header-section-number">7.8.1</span> Forecasting with a nonlinear trend</h3>
<p>In section <a href="time-series-regression-models.html#some-useful-predictors">7.4</a> we introduce the trend variable <span class="math inline">\(t\)</span>. The simplest way of fitting a nonlinear trend is using quadratic or higher order trends obtained by specifying</p>
<p><span class="math display">\[
x_{1t} = t, \;\;\;x_{2t} = t^2, \;\;\;\dots
\]</span></p>
<p>In practice, higher order (<span class="math inline">\(&gt;3\)</span>) or even quadratic terms are not recommended in forecasting. When they are extrapolated, the resulting forecasts are often unrealistic.</p>
<p>A better approach is to use the piecewise specification introduced above and fit a piecewise linear trend which bends at some point in time. We can think of this as a nonlinear trend constructed of linear pieces. If the trend bends at time <span class="math inline">\(\tau\)</span>, then it can be specified by simply replacing <span class="math inline">\(x=t\)</span> and <span class="math inline">\(c=τ\)</span> above such that we include the predictors</p>
<p><span class="math display">\[
\begin{aligned}
x_{1t} &amp;= t \\
x_{2t} = (t - \tau)_+ &amp;= 
\begin{cases}
0 &amp; t &lt; \tau \\  
(t - \tau) &amp; t \ge \tau
\end{cases}
\end{aligned}
\]</span>
in the model.</p>
</div>
<div id="example-boston-marathon-winning-times" class="section level3">
<h3><span class="header-section-number">7.8.2</span> Example: Boston marathon winning times</h3>
<p>We will fit some trend models to the Boston marathon winning times for men since the event started in 1897.</p>
<div class="sourceCode" id="cb141"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb141-1"><a href="time-series-regression-models.html#cb141-1"></a>boston_men &lt;-<span class="st"> </span>fpp3<span class="op">::</span>boston_marathon <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb141-2"><a href="time-series-regression-models.html#cb141-2"></a><span class="st">  </span><span class="kw">filter</span>(Event <span class="op">==</span><span class="st"> &quot;Men&#39;s open division&quot;</span>) <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb141-3"><a href="time-series-regression-models.html#cb141-3"></a><span class="st">  </span><span class="kw">mutate</span>(<span class="dt">Minutes =</span> <span class="kw">as.numeric</span>(Time) <span class="op">/</span><span class="st"> </span><span class="dv">60</span>)</span>
<span id="cb141-4"><a href="time-series-regression-models.html#cb141-4"></a></span>
<span id="cb141-5"><a href="time-series-regression-models.html#cb141-5"></a>boston_lm &lt;-<span class="st"> </span>boston_men <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb141-6"><a href="time-series-regression-models.html#cb141-6"></a><span class="st">  </span><span class="kw">model</span>(<span class="kw">TSLM</span>(Minutes <span class="op">~</span><span class="st"> </span><span class="kw">trend</span>())) </span>
<span id="cb141-7"><a href="time-series-regression-models.html#cb141-7"></a></span>
<span id="cb141-8"><a href="time-series-regression-models.html#cb141-8"></a>boston_men <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb141-9"><a href="time-series-regression-models.html#cb141-9"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(Year, Minutes)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb141-10"><a href="time-series-regression-models.html#cb141-10"></a><span class="st">  </span><span class="kw">geom_line</span>() <span class="op">+</span><span class="st"> </span></span>
<span id="cb141-11"><a href="time-series-regression-models.html#cb141-11"></a><span class="st">  </span><span class="kw">geom_smooth</span>(<span class="dt">method =</span> <span class="st">&quot;lm&quot;</span>, <span class="dt">se =</span> <span class="ot">FALSE</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb141-12"><a href="time-series-regression-models.html#cb141-12"></a><span class="st">  </span><span class="kw">geom_vline</span>(<span class="dt">xintercept =</span> <span class="kw">c</span>(<span class="dv">1940</span>, <span class="dv">1980</span>), <span class="dt">size =</span> <span class="fl">1.5</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb141-13"><a href="time-series-regression-models.html#cb141-13"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Fitting a linear line&quot;</span>)</span>
<span id="cb141-14"><a href="time-series-regression-models.html#cb141-14"></a>  </span>
<span id="cb141-15"><a href="time-series-regression-models.html#cb141-15"></a>boston_lm <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb141-16"><a href="time-series-regression-models.html#cb141-16"></a><span class="st">  </span><span class="kw">augment</span>() <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb141-17"><a href="time-series-regression-models.html#cb141-17"></a><span class="st">  </span><span class="kw">ggplot</span>(<span class="kw">aes</span>(Year, .resid)) <span class="op">+</span><span class="st"> </span></span>
<span id="cb141-18"><a href="time-series-regression-models.html#cb141-18"></a><span class="st">  </span><span class="kw">geom_point</span>() <span class="op">+</span><span class="st"> </span></span>
<span id="cb141-19"><a href="time-series-regression-models.html#cb141-19"></a><span class="st">  </span><span class="kw">geom_hline</span>(<span class="dt">yintercept =</span> <span class="dv">0</span>, <span class="dt">size =</span> <span class="fl">1.5</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb141-20"><a href="time-series-regression-models.html#cb141-20"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Residual across trend&quot;</span>)</span></code></pre></div>
<p><img src="ch7_files/figure-html/unnamed-chunk-36-1.png" width="100%" style="display: block; margin: auto;" /><img src="ch7_files/figure-html/unnamed-chunk-36-2.png" width="100%" style="display: block; margin: auto;" /></p>
<div class="sourceCode" id="cb142"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb142-1"><a href="time-series-regression-models.html#cb142-1"></a>boston_lm <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">glance</span>()</span>
<span id="cb142-2"><a href="time-series-regression-models.html#cb142-2"></a><span class="co">#&gt; # A tibble: 1 x 16</span></span>
<span id="cb142-3"><a href="time-series-regression-models.html#cb142-3"></a><span class="co">#&gt;   Event .model r_squared adj_r_squared sigma2 statistic  p_value    df log_lik</span></span>
<span id="cb142-4"><a href="time-series-regression-models.html#cb142-4"></a><span class="co">#&gt;   &lt;fct&gt; &lt;chr&gt;      &lt;dbl&gt;         &lt;dbl&gt;  &lt;dbl&gt;     &lt;dbl&gt;    &lt;dbl&gt; &lt;int&gt;   &lt;dbl&gt;</span></span>
<span id="cb142-5"><a href="time-series-regression-models.html#cb142-5"></a><span class="co">#&gt; 1 Men&#39;~ TSLM(~     0.728         0.726   38.2      324. 4.82e-36     2   -398.</span></span>
<span id="cb142-6"><a href="time-series-regression-models.html#cb142-6"></a><span class="co">#&gt; # ... with 7 more variables: AIC &lt;dbl&gt;, AICc &lt;dbl&gt;, BIC &lt;dbl&gt;, CV &lt;dbl&gt;,</span></span>
<span id="cb142-7"><a href="time-series-regression-models.html#cb142-7"></a><span class="co">#&gt; #   deviance &lt;dbl&gt;, df.residual &lt;int&gt;, rank &lt;int&gt;</span></span></code></pre></div>
<p>There seems to be a (quadratic) pattern in our residual plot, and our simple linear model isn’t fitting very well.</p>
<p>Alternatively, fitting an exponential trend (equivalent to a log-linear regression) to the data can be achieved by transforming the <span class="math inline">\(y\)</span> variable so that the model to be fitted is,</p>
<p><span class="math display">\[
\log{y}_t = \beta_0 + \beta_1t + \varepsilon_t
\]</span></p>
<p>The plot of winning times reveals three different periods. There is a lot of volatility in the winning times up to about 1940, with the winning times decreasing overall but with significant increases during the 1920s. After 1940 there is a near-linear decrease in times, followed by a flattening out after the 1980s, with the suggestion of an upturn towards the end of the sample. To account for these changes, <strong>we specify the years 1940 and 1980 as knots</strong>. We should warn here that subjective identification of knots can lead to over-fitting, which can be detrimental to the forecast performance of a model, and should be performed with caution.</p>
<p>A piecewise regression (bends at certain time <span class="math inline">\(t\)</span>) is specified using the <code>knots</code> argument in <code>trend()</code>:</p>
<div class="sourceCode" id="cb143"><pre class="sourceCode r"><code class="sourceCode r"><span id="cb143-1"><a href="time-series-regression-models.html#cb143-1"></a>boston_piece_fit &lt;-<span class="st"> </span>boston_men <span class="op">%&gt;%</span><span class="st"> </span></span>
<span id="cb143-2"><a href="time-series-regression-models.html#cb143-2"></a><span class="st">  </span><span class="kw">model</span>(</span>
<span id="cb143-3"><a href="time-series-regression-models.html#cb143-3"></a>    <span class="dt">linear =</span> <span class="kw">TSLM</span>(Minutes <span class="op">~</span><span class="st"> </span><span class="kw">trend</span>()),</span>
<span id="cb143-4"><a href="time-series-regression-models.html#cb143-4"></a>    <span class="dt">exponential =</span> <span class="kw">TSLM</span>(<span class="kw">log</span>(Minutes) <span class="op">~</span><span class="st"> </span><span class="kw">trend</span>()),</span>
<span id="cb143-5"><a href="time-series-regression-models.html#cb143-5"></a>    <span class="dt">piecewise =</span> <span class="kw">TSLM</span>(Minutes <span class="op">~</span><span class="st"> </span><span class="kw">trend</span>(<span class="dt">knots =</span> <span class="kw">c</span>(<span class="dv">1940</span>, <span class="dv">1980</span>)))</span>
<span id="cb143-6"><a href="time-series-regression-models.html#cb143-6"></a>  )</span>
<span id="cb143-7"><a href="time-series-regression-models.html#cb143-7"></a></span>
<span id="cb143-8"><a href="time-series-regression-models.html#cb143-8"></a>boston_piece_fc &lt;-<span class="st"> </span>boston_piece_fit <span class="op">%&gt;%</span><span class="st"> </span><span class="kw">forecast</span>(<span class="dt">h =</span> <span class="dv">10</span>) </span>
<span id="cb143-9"><a href="time-series-regression-models.html#cb143-9"></a></span>
<span id="cb143-10"><a href="time-series-regression-models.html#cb143-10"></a>boston_piece_fc <span class="op">%&gt;%</span></span>
<span id="cb143-11"><a href="time-series-regression-models.html#cb143-11"></a><span class="st">  </span><span class="kw">autoplot</span>(boston_men, <span class="dt">level =</span> <span class="ot">NULL</span>) <span class="op">+</span><span class="st"> </span></span>
<span id="cb143-12"><a href="time-series-regression-models.html#cb143-12"></a><span class="st">  </span><span class="kw">labs</span>(<span class="dt">title =</span> <span class="st">&quot;Boston Marathon&quot;</span>, </span>
<span id="cb143-13"><a href="time-series-regression-models.html#cb143-13"></a>       <span class="dt">x =</span> <span class="st">&quot;Year&quot;</span>, </span>
<span id="cb143-14"><a href="time-series-regression-models.html#cb143-14"></a>       <span class="dt">y =</span> <span class="st">&quot;Winning times in minutes&quot;</span>,</span>
<span id="cb143-15"><a href="time-series-regression-models.html#cb143-15"></a>       <span class="dt">color =</span> <span class="st">&quot;Model&quot;</span>)</span></code></pre></div>
<p><img src="ch7_files/figure-html/unnamed-chunk-38-1.png" width="100%" style="display: block; margin: auto;" /></p>
</div>
</div>
<div id="correlation-causation-and-forecasting" class="section level2">
<h2><span class="header-section-number">7.9</span> Correlation, causation and forecasting</h2>

</div>
</div>
            </section>

          </div>
        </div>
      </div>
<a href="judgmental-forecasts.html" class="navigation navigation-prev " aria-label="Previous page"><i class="fa fa-angle-left"></i></a>
<a href="exponential-smoothing.html" class="navigation navigation-next " aria-label="Next page"><i class="fa fa-angle-right"></i></a>
    </div>
  </div>
<script src="libs/gitbook-2.6.7/js/app.min.js"></script>
<script src="libs/gitbook-2.6.7/js/lunr.js"></script>
<script src="libs/gitbook-2.6.7/js/clipboard.min.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-search.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-sharing.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-fontsettings.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-bookdown.js"></script>
<script src="libs/gitbook-2.6.7/js/jquery.highlight.js"></script>
<script src="libs/gitbook-2.6.7/js/plugin-clipboard.js"></script>
<script>
gitbook.require(["gitbook"], function(gitbook) {
gitbook.start({
"sharing": {
"github": false,
"facebook": true,
"twitter": true,
"linkedin": false,
"weibo": false,
"instapaper": false,
"vk": false,
"all": ["facebook", "twitter", "linkedin", "weibo", "instapaper"]
},
"fontsettings": {
"theme": "white",
"family": "serif",
"size": 2
},
"edit": {
"link": "https://github.com/enixam/fpp/edit/master/ch7.Rmd",
"text": "Edit"
},
"history": {
"link": null,
"text": null
},
"view": {
"link": null,
"text": null
},
"download": null,
"toc": {
"collapse": "subsection"
}
});
});
</script>

<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    var src = "true";
    if (src === "" || src === "true") src = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML";
    if (location.protocol !== "file:")
      if (/^https?:/.test(src))
        src = src.replace(/^https?:/, '');
    script.src = src;
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>
</body>

</html>
