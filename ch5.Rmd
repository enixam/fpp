
# The forecaster's toolbox   

```{r}
library(tsibble)
library(tsibbledata)
library(fable)
library(feasts)
library(lubridate)
```


## A tidy forecasting workflow  

```{r, echo = FALSE}
knitr::include_graphics("images/workflow.png")
```


### Data preparation (tidy)  


### Visualize   

```{r}
global_economy %>%
  filter(Country == "Sweden") %>%
  autoplot(GDP) +
  scale_y_continuous(labels = scales::label_number_si()) + 
  ggtitle("GDP for Sweden") + ylab("$US billions")
```

### Define a model (specify)  

A model defination  

```{r}
TSLM(GDP ~ trend())
```

`TSLM()` specifies a time series linear model.  

Similar to `tidymodels`: 

```{r}
library(parsnip)
linear_reg() %>% 
  set_engine("lm") %>% 
  set_mode("regression")
```

### Train the model (estimate)  

```{r, cache = TRUE}
ge_fit <- global_economy %>% 
  model(trend_model = TSLM(GDP ~ trend()))

ge_fit
```

### Check model performance (evaluate)  



### Produce forecasts (forecast)  

Similar to `predict()`: 

```{r, cache = TRUE}
ge_forecast <- ge_fit %>% 
  forecast(h = "3 years") # h means horizon

ge_forecast
```

```{r, cache = TRUE}
ge_forecast %>% 
  filter(Country == "Sweden") %>% 
  autoplot(global_economy) + 
  scale_y_continuous(labels = scales::label_number_si()) + 
  ggtitle("GDP for Sweden")
```

## Some simple forecasting methods  

Some forecasting methods are extremely simple and surprisingly effective. We will use four simple forecasting methods as benchmarks throughout this book.

To illustrate them, we will use quarterly Australian clay brick production between 1970 and 2004.  

```{r}
bricks <- aus_production %>% filter_index("1970" ~ "2004")
bricks
```

### Mean method  

Here, the forecasts of **all future values** are equal to the **average** (or “mean”) of the historical data. If we let the historical data be denoted by $y_1,…,y_T$, then we can write the forecasts as 

$$
\hat{y}_{T+H | T} = \frac{1}{T}\sum_{1}^{T}{y_t}
$$

`MEAN()` specifies an average model:  

```{r}
bricks %>% 
  model(MEAN(Bricks)) %>% 
  forecast(h = "5 years") %>% 
  autoplot(bricks)
```

### Naive methods  

For naive forecasts, we simply set **all forecasts** to be the value of the **last observation**. That is,   

$$
\hat{y}_{T+H | T} = y_T
$$ 

This method works remarkably well for many economic and financial time series. 
 
Because a naive forecast is optimal when data follow a random walk (see Section 9.1), these are also called **random walk** forecasts.   

`NAIVE()` specifies a naive model:  

```{r, message = TRUE}
bricks %>% 
  model(NAIVE(Bricks)) %>% 
  forecast(h = "5 years") %>% 
  autoplot(bricks)
```

### Seasonal naive method  

Seasonal naïve method

A similar method is useful for highly seasonal data. In this case, we set each forecast to be equal to the last observed value from the same season of the year (e.g., the same month of the previous year). Formally, the forecast for time $T+h$ is written as 

$$
\hat{y}_{T+H | T} = y_{T + H - m(k + 1)}
$$

where $m$ is for seaonsal period (e.g., 12 for monthly data, 4 for quarterly data), and $k$ is the interger part of $(h - 1) / m$  

```{r}
bricks %>% 
  model(SNAIVE(Bricks ~ lag("year"))) %>% 
  forecast(h = "5 years") %>% 
  autoplot(bricks, level = NULL)
```


The `lag()` function is optional here as bricks is monthly data and so a seasonal naïve model will need a one-year lag. However, for some time series there is more than one seasonal period, and then the required lag must be specified.  


### Drift method  

A variation on the naive method is to allow the forecasts to increase or decrease over time, where the amount of change over time (called the **drift**, which is the slope of the line between the first and last obeservation) is set to be the average change seen in the historical data. Thus the forecast for time T+h is given by:  


$$
y_{T+h} - y_{T} = \frac{y_{T} - y_1}{T - 1}[(T + h) - T) 
$$

$$
y_{T+h} = y_T + h(\frac{y_{T} - y_1}{T - 1})
$$


```{r, cache = TRUE}
bricks %>% 
  model(NAIVE(Bricks ~ drift())) %>%
  forecast(h = "10 years") %>% 
  autoplot(bricks, level = NULL)
```


### Australian quarterly beer production  

```{r, cache = TRUE}
beer_fit <- aus_production %>% 
  filter_index("1992 Q1" ~ "2006 Q4") %>% 
  model(Mean = MEAN(Beer),
        naive = NAIVE(Beer),
        seasonal_naive = SNAIVE(Beer))

beer_fit %>% 
  forecast(h = 14) %>%  # 14 quarters
  autoplot(aus_production %>% filter_index("1992 Q1" ~ "2006 Q4"), level = NULL) + 
  autolayer(aus_production %>% filter_index("2007 Q1" ~ .), color = "black")
```


In this case, only the seasonal naïve forecasts are close to the observed values from 2007 onwards.


### Example: Google’s daily closing stock price  


```{r, cache = TRUE}
# Re-index based on trading days
google_stock <- gafa_stock %>%
  filter(Symbol == "GOOG") %>%
  mutate(day = row_number()) %>%
  update_tsibble(index = day, regular = TRUE)
# Filter the year of interest
google_2015 <- google_stock %>% 
  filter(year(Date) == 2015)
# Fit the models
google_fit <- google_2015 %>%
  model(
    Mean = MEAN(Close),
    naive = NAIVE(Close),
    drift = NAIVE(Close ~ drift())
  )

# Produce forecasts for the 19 trading days in January 2015
google_fc <- google_fit %>% forecast(h = 19)
# A better way using a tsibble to determine the forecast horizons
google_jan_2016 <- google_stock %>%
  filter(yearmonth(Date) == yearmonth("2016 Jan"))
google_fc <- google_fit %>% forecast(google_jan_2016)

# Plot the forecasts
google_fc %>%
  autoplot(google_2015, level = NULL) +
    autolayer(google_jan_2016, Close, color='black') +
    ggtitle("Google stock (daily ending 31 Dec 2015)") +
    xlab("Day") + ylab("Closing Price (US$)") +
    guides(colour=guide_legend(title="Forecast"))
```
Sometimes one of these simple methods will be the best forecasting method available; but in many cases, **these methods will serve as benchmarks rather than the method of choice**. That is, any forecasting methods we develop will be compared to these simple methods to ensure that the new method is better than these simple alternatives. If not, the new method is not worth considering.  


## Fitted values and residuals  

Each observation in a time series can be forecast using all previous observations. We call these **fitted values** and they are denoted by $\hat{y}_{t|t−1}$, meaning the forecast of yt based on observations $y_1,\dots,y_t−1$ . We use these so often, we sometimes drop part of the subscript and just write $\hat{y}_t$ instead of $\hat{y}_{t|t−1}$. Fitted values always involve one-step forecasts.  

Actually, fitted values are often not true forecasts because any parameters involved in the forecasting method are estimated using all available observations in the time series, including future observations. For example, if we use the average method, the fitted values are given by 

$$
\hat{y}_t= \hat{c} 
$$
where $\hat{c} = \frac{1}{T}\sum_{t = 1}^{T}y_t$, meaning that it is computed across **all available observations**, including those at times after $t$. 

Similarly, for the drift method, the drift parameter is estimated using all available observations. In this case, the fitted values are given by 

$$
\hat{y}_t = y_{t-1} + \hat{c} 
$$
where $\hat{c} = \frac{y_T - y_1}{T-1}$, the "overall slope".

In both cases, there is a parameter to be estimated from the data. The “hat $\hat{}$” above the $c$ reminds us that this is an estimate. **When the estimate of $c$ involves observations after time $t$, the fitted values are not true forecasts.** On the other hand, naïve or seasonal naïve forecasts do not involve any parameters, and so fitted values are true forecasts in such cases.  

### Residuals  

$$
e_t = y_t - \hat{y}_t
$$


```{r}
augment(beer_fit)
```

## Residual diagnostics  

A good forecasting method will yield residuals with the following properties:  

1. The residuals are **uncorrelated.** If there are correlations between residuals, then there is information left in the residuals which should be used in computing forecasts.  
2. The residuals have **zero mean**(i.e., $E(e) = 0$. If the residuals have a mean other than zero, then the forecasts are biased.  

Any forecasting method that does not satisfy these properties can be improved. However, that does not mean that forecasting methods that satisfy these properties cannot be improved. It is possible to have several different forecasting methods for the same data set, all of which satisfy these properties. Checking these properties is important in order to see whether a method is using all of the available information, but it is not a good way to select a forecasting method.

If either of these properties is not satisfied, then the forecasting method can be modified to give better forecasts. Adjusting for bias is easy: if the residuals have mean $m$
, then simply add $m$ to all forecasts and the bias problem is solved. Fixing the correlation problem is harder, and we will not address it until Chapter 10.  

In addition to these essential properties, it is useful (but not necessary) for the residuals to also have the following two properties.

> 3. The residuals have **constant variance**.  
> 4. The residuals are **normally distributed**.

These two properties make the calculation of prediction intervals easier (see Section 5.5 for an example). However, a forecasting method that does not satisfy these properties cannot necessarily be improved. Sometimes applying a Box-Cox transformation may assist with these properties, but otherwise there is usually little that you can do to ensure that your residuals have constant variance and a normal distribution. Instead, an alternative approach to obtaining prediction intervals is necessary. Again, we will not address how to do this until later in the book.  

### Example: Forecasting the Google daily closing stock price  

We will continue with the Google daily closing stock price example from the previous chapter. For stock market prices and indexes, the best forecasting method is often the naïve method. That is, each forecast is simply equal to the last observed value, or $\hat{y}_t = y_{t−1}$. Hence, the residuals are simply equal to the difference between consecutive observations:   

$$
e_t = y_t - \hat{y}_t = y_t - y_{t-1} 
$$

The following graph shows the Google daily closing stock price for trading days during 2015. The large jump corresponds to 17 July 2015 when the price jumped 16% due to unexpectedly strong second quarter results.  

```{r}
google_2015 %>% autoplot(Close) +
  xlab("Day") + ylab("Closing Price (US$)") +
  ggtitle("Google Stock in 2015")
```


```{r}
aug <- google_2015 %>% model(NAIVE(Close)) %>% augment()
aug %>% autoplot(.resid) + xlab("Day") + ylab("") +
  ggtitle("Residuals from naïve method")

aug %>% 
  ggplot() + 
  geom_histogram(aes(.resid))

aug %>% 
  ACF(.resid) %>%
  autoplot()
```

Shorthand function:  

```{r}
google_2015 %>%
  model(naive = NAIVE(Close)) %>% 
  gg_tsresiduals()
```

### Portmanteau tests for autocorrelation

```{r}
aug %>% 
  ggplot(aes(sample = .resid)) + 
  stat_qq() + 
  stat_qq_line()
```

### Portmanteau tests for autocorrelation



n order to overcome this problem, we test whether the first h autocorrelations are significantly different from what would be expected from a white noise process. A test for a group of autocorrelations is called a **portmanteau test**, from a French word describing a suitcase containing a number of items.  

One such test is the **Box-Pierce** test, based on the following statistic:  

$$
Q = T \sum_{k = 1}^{h}{r^2_k}
$$


where $h$ is the maximum lag being considered and $T$ is the number of observations. If each $r_k$ is close to zero, then $Q$ will be small. If some $r_k$ values are large (positive or negative), then $Q$ will be large. We suggest using $h = 10$ for non-seasonal data and $h = 2m$ for seasonal data, where $m$ is the period of seasonality. However, the test is not good when $h$ is large, so if these values are larger than $T/5$, then use $h=T/5$.  

A related (and more accurate) test is the **Ljung-Box test**, based on 

$$
Q^* = T(T + 2)\sum_{k = 1}^{h}{(T-K)^{-1}}r_k^2
$$

 If the autocorrelations did come from a white noise series, then both $Q$ and $Q^*$ follows a  distribution of $\chi^2_{h - K}$ where $K$ is the number of parameters in the model. For naive model where there is no parameter to estimate, we simply set $K = 0$.  

```{r}
# lag = h and fitdf = K
aug %>% features(.resid, box_pierce, lag = 10, dof = 0)

aug %>% features(.resid, ljung_box, lag = 10, dof = 0)
```

For both $Q$ and $Q^∗$, the results are not significant. Thus, we can conclude that the residuals are not distinguishable from a white noise series.  


## Prediction intervals 


